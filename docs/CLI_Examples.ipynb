{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Comandi Make Utili\n",
    "\n",
    "Il progetto include un `Makefile` per semplificare le operazioni comuni. Ecco alcune combinazioni utili:\n",
    "\n",
    "- **`make refresh`**: Rigenera il CSV dai JSON esistenti e avvia immediatamente la dashboard. Utile se hai modificato manualmente dei JSON o se vuoi vedere subito i cambiamenti senza rieseguire l'analisi.\n",
    "- **`make full`**: Esegue l'intero ciclo: analisi dei PDF (`run`), rigenerazione del CSV (`csv`) e avvio della dashboard (`dashboard`).\n",
    "- **`make backfill`**: Esegue uno script specifico per recuperare metadati mancanti usando un LLM.\n",
    "\n",
    "Per vedere tutti i comandi disponibili, esegui `make help` nel terminale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Guida al Workflow di Analisi PTOF\n",
    "\n",
    "Questo notebook esegue l'intero processo di analisi dei PTOF (Piani Triennali dell'Offerta Formativa) utilizzando un'architettura multi-agente.\n",
    "\n",
    "## üîÑ Flusso di Lavoro\n",
    "\n",
    "1.  **Input**: I file PDF vengono letti dalla cartella `ptof_inbox/`.\n",
    "2.  **Conversione**: I PDF vengono convertiti in Markdown (`ptof_md/`) per essere leggibili dagli agenti AI.\n",
    "3.  **Analisi AI**: Una catena di agenti (Analyst, Refiner, Reviewer, Synthesizer) analizza il contenuto e produce un JSON strutturato (`analysis_results/`).\n",
    "4.  **Arricchimento**: I dati vengono arricchiti con metadati ufficiali (MIUR) e calcolati indici di maturit√†.\n",
    "5.  **Consolidamento**: Tutti i JSON vengono aggregati in un unico file CSV (`data/analysis_summary.csv`) che alimenta la Dashboard.\n",
    "6.  **Archiviazione**: I PDF processati con successo vengono spostati in `ptof_processed/`.\n",
    "\n",
    "## üìÇ File e Cartelle Coinvolti\n",
    "\n",
    "| Percorso | Descrizione |\n",
    "| :--- | :--- |\n",
    "| `ptof_inbox/` | **Input**: Copia qui i file PDF dei PTOF da analizzare. |\n",
    "| `ptof_md/` | **Intermedio**: Contiene le conversioni in testo Markdown dei PDF. |\n",
    "| `analysis_results/` | **Output JSON**: Contiene un file JSON per ogni scuola analizzata (Fonte di Verit√†). |\n",
    "| `data/analysis_summary.csv` | **Output CSV**: File riassuntivo generato dai JSON, usato dalla Dashboard. |\n",
    "| `ptof_processed/` | **Archivio**: Dove finiscono i PDF dopo essere stati analizzati. |\n",
    "| `src/processing/rebuild_csv_clean.py` | **Script**: Rigenera il CSV partendo dai JSON esistenti. |\n",
    "| `app/Home.py` | **Dashboard**: Applicazione Streamlit per visualizzare i dati. |\n",
    "\n",
    "## üöÄ Come Eseguire\n",
    "\n",
    "1.  Assicurati di aver copiato i PDF in `ptof_inbox/`.\n",
    "2.  Esegui la cella di codice sottostante.\n",
    "3.  Attendi il completamento di tutti gli step.\n",
    "4.  Avvia la dashboard con `streamlit run app/Home.py` (o usa il comando `make dashboard` da terminale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ WORKFLOW COMPLETO ANALISI PTOF\n",
      "üïê 2025-12-23 14:28:33\n",
      "======================================================================\n",
      "\n",
      "üîß Caricamento database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:28:34,300 - INFO - [SchoolDatabase] Loaded 61855 schools.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SchoolDatabase] Loaded 61855 schools from CSVs.\n",
      "   ‚úÖ Database MIUR: 61855 scuole\n",
      "\n",
      "üì• PDF in inbox: 117\n",
      "\n",
      "======================================================================\n",
      "üîç STEP 0: Validazione codici meccanografici\n",
      "======================================================================\n",
      "‚úÖ RMIS02400L: Istruzione Superiore Via Delle Scienze\n",
      "‚ùå linee_di_indirizzo_del_DS_202210241729.pdf: Codice non estratto\n",
      "üîé PTOF_2024-25.pdf: codice estratto dal PDF ‚Üí NAPS36000R\n",
      "‚úÖ NAPS36000R: L.Scient.\"Carlo Urbani\"San Giorgio A Cr.\n",
      "‚úÖ CEIC87400L: I.C. Di San Marcellino\n",
      "‚úÖ AGPC010001: Liceo Classico - Empedocle\n",
      "üîé PTOF-Marconi-Mangano-2022-25.pdf: codice estratto dal PDF ‚Üí CTIS04300B\n",
      "‚ö†Ô∏è PTOF-Marconi-Mangano-2022-25.pdf: codici trovati ['CTIS04300B', 'CTTF04301X', 'CTTF043508', 'CTRF043014', 'CTRF04350C'], scelto CTIS04300B\n",
      "‚úÖ CTIS04300B: Marconi-Mangano\n",
      "‚úÖ MOIC84900D: 2 I.C. Ravarino\n",
      "‚úÖ BAIC89400E: I.C. \"De Amicis-Giovanni Xxiii\"\n",
      "‚úÖ VTIC82500A: I.C. Capranica\n",
      "‚úÖ PATDEE500L: Niccolo' Machiavelli\n",
      "‚úÖ RMIS01600N: Via Delle Sette Chiese 259\n",
      "‚úÖ PEIS00300X: Iis \"E.Alessandrini\" Montesilvano\n",
      "üîé CAGLIARI_CAIC86800V.pdf: codice estratto dal PDF ‚Üí CAIC8AM00E\n",
      "‚ö†Ô∏è CAGLIARI_CAIC86800V.pdf: codici trovati ['CAIC86800V', 'CAIC8AM00E'], scelto CAIC8AM00E\n",
      "‚úÖ CAIC8AM00E: Ugo Foscolo - Via Stoccolma\n",
      "üîé BNIS01100L_PTOF.pdf: codice estratto dal PDF ‚Üí LEPC13000N\n",
      "‚ö†Ô∏è BNIS01100L_PTOF.pdf: codici trovati ['BNIS01100L', 'LEPC13000N', 'LEPC130001'], scelto LEPC13000N\n",
      "‚úÖ LEPC13000N: Liceo \"Virgilio-Redi\"\n",
      "‚úÖ RMIC8GA002: Ic Via P. Stabilini\n",
      "‚úÖ TOPS10000T: Charles Darwin\n",
      "‚úÖ PAIC888009: Ic. Trabia -Giovanni Xxiii\n",
      "‚úÖ MSIC81200D: I.C. \"Massa 6\" Loc. Romagnano\n",
      "‚úÖ MIRFHT500U: Barbara Melzi\n",
      "‚úÖ PAPS3Q5009: Istituto Gonzaga\n",
      "‚úÖ PRIS00200Q: I.S.I.S.S. \"Galilei-Bocchialini\"\n",
      "üîé PTOF_2025-28_scelte_strategiche.pdf: codice estratto dal PDF ‚Üí TRMM045005\n",
      "‚úÖ TRMM045005: Terni \"L. Da Vinci E O. Nucula\"\n",
      "‚úÖ BOIS02700V: I.I.S. Crescenzi-Pacinotti-Sirani\n",
      "‚úÖ NARH105008: Maria Montessori\n",
      "üîé CSIC80800Q_PTOF.pdf: codice estratto dal PDF ‚Üí VE1M6Q5004\n",
      "‚ö†Ô∏è CSIC80800Q_PTOF.pdf: codici trovati ['CSIC80800Q', 'VE1M6Q5004'], scelto VE1M6Q5004\n",
      "‚úÖ VE1M6Q5004: Santa Caterina Da Siena\n",
      "‚úÖ PAPC030004: Meli\n",
      "‚úÖ AQIS01800Q: I.I.S \"A. Bafile\"\n",
      "‚úÖ LEIC887006: I.C. Galatina Polo 1\n",
      "‚úÖ FRPC02500X: S.Bernardo\n",
      "‚úÖ SRTL49500I: Istituto Paritario \"S. Quasimodo\"\n",
      "üîé PTOF_2025-28-a.s.-24-25_Timbro.pdf: codice estratto dal PDF ‚Üí PZIS029003\n",
      "‚úÖ PZIS029003: I.O. \"E. Majorana\" Genzano Di Lucania\n",
      "‚úÖ RMPL355003: L.Ling. Mons. Tozzi\n",
      "‚úÖ UD1M00600L: Scuola Secondaria I Grado Paritaria G. Bearzi\n",
      "‚úÖ BG1M02700A: Scuola Sec. 1¬∞ Grado \"Sacro Cuore\"\n",
      "‚úÖ RMIS09400V: Pacinotti - Archimede\n",
      "‚úÖ TOIC8A100T: I.C. Vittorino Da Feltre - To\n",
      "‚ùå PTOF iniziale 25_28.pdf: Codice non estratto\n",
      "‚úÖ VIPS08000D: L.S. \"Da Vinci\" Arzignano\n",
      "üîé MATERA_MTIS009001.pdf: codice estratto dal PDF ‚Üí MTIS009001\n",
      "‚ö†Ô∏è MATERA_MTIS009001.pdf: codici trovati ['MTIS009001', 'ELLALEGGE2', 'AGOSTO2019', 'IANOCOMEL2'], scelto MTIS009001\n",
      "‚ö†Ô∏è MTIS009001: Non in MIUR (procedo comunque)\n",
      "‚úÖ MEIS03700V: I.I.S. \"A.M.Jaci - Caio Duilio\"\n",
      "‚úÖ PAIC87200Q: I.C. Padre Puglisi - Orestano\n",
      "‚úÖ TAIC829004: I.C. \"G. Salvemini\"\n",
      "‚úÖ VR1A23500E: Scuola Materna A.Provolo-Centro Infanzia\n",
      "‚úÖ SRIC823006: I I.C. \"Pirandello\" Carlentini\n",
      "‚úÖ RMIS02400L: Istruzione Superiore Via Delle Scienze\n",
      "‚ö†Ô∏è Duplicato RMIS02400L: tengo PTOF_RMIS02400L-2025-2028_def.pdf, scarto COLLEFERRO_RMIS02400L.pdf\n",
      "‚úÖ FGIC86200B: I.C. \"G. Catalano - Moscati\"\n",
      "‚ùå PTOF-2022-25-.pdf: Codice non estratto\n",
      "üîé PTOF 2025-28 scelte strategiche.pdf: codice estratto dal PDF ‚Üí TRMM045005\n",
      "‚úÖ TRMM045005: Terni \"L. Da Vinci E O. Nucula\"\n",
      "‚ö†Ô∏è Duplicato TRMM045005: tengo PTOF_2025-28_scelte_strategiche.pdf, scarto PTOF 2025-28 scelte strategiche.pdf\n",
      "‚úÖ CHIC80700E: I.C. Fossacesia \"P.D.Pollidori\"\n",
      "üîé PTOF-2025-2028-3.pdf: codice estratto dal PDF ‚Üí RMIC8FA00B\n",
      "‚úÖ RMIC8FA00B: Ic Via Casale Del Finocchio\n",
      "‚úÖ BGPS02000G: \"Filippo Lussana\"\n",
      "‚ùå PTOF_TADDIA_2019-2022 .pdf: Codice non estratto\n",
      "‚úÖ AGIS00100X: Iis - Ugo Foscolo\n",
      "üîé PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028.pdf: codice estratto dal PDF ‚Üí ME1A14100N\n",
      "‚ö†Ô∏è PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028.pdf: codici trovati ['ME1A14100N', 'ME1E016002', 'ME1EOF500O', 'ME1M00500R', 'ME1MU5500F', 'MEPMEB500L', 'MEPS01500B', 'MEPS435000', 'MEPCPD5001'], scelto ME1A14100N\n",
      "‚úÖ ME1A14100N: S. Ignazio\n",
      "üîé PTOF-TRIENNIO-2025-2028.pdf: codice estratto dal PDF ‚Üí NASD04000B\n",
      "‚úÖ NASD04000B: Liceo Artistico Statale-\"G. De Chirico\"\n",
      "‚úÖ GEIS01400Q: I.S. I. Calvino\n",
      "‚úÖ MOIS00200C: Primo Levi\n",
      "‚úÖ CHIS019001: Iis \"De Titta - Fermi\" - Lanciano\n",
      "‚úÖ SOPS050001: Liceo P.Nervi - G.Ferrari\n",
      "‚úÖ MTIS01200R: I.I.S. \" G.B. Pentasuglia \" -Matera\n",
      "‚úÖ CNIS01100D: Ceva - \"G. Baruffi\"\n",
      "‚úÖ MIPC09500C: Liceo Classico Istituto Gonzaga\n",
      "‚úÖ BAIC818001: I.C. \"Massari Galilei\"\n",
      "‚úÖ BORC10500R: Istituto Salesiano Beata Vergine Di San Luca\n",
      "üîé PTOF-completo-25-28.pdf: codice estratto dal PDF ‚Üí GERI015006\n",
      "‚ö†Ô∏è PTOF-completo-25-28.pdf: codici trovati ['IT08D05387', 'IT73V05034', 'GERI015006'], scelto GERI015006\n",
      "‚úÖ GERI015006: Duchessa Di Galliera\n",
      "‚úÖ TEIS012009: I.I.S. Delfico-Montauti\n",
      "‚úÖ CEPS02000T: Ls Enrico Fermi Aversa\n",
      "‚úÖ MIRFHT500U: Barbara Melzi\n",
      "‚ö†Ô∏è Duplicato MIRFHT500U: tengo PTOF-MIRFHT500U-202225-rev.-2024-25.pdf, scarto MIRFHT500U_PTOF.pdf\n",
      "‚úÖ VAPLVL5003: Liceo Linguistico Collegio Rotondi\n",
      "‚úÖ MIIC836006: Ic Don Lorenzo Milani\n",
      "‚úÖ PAIC87200Q: I.C. Padre Puglisi - Orestano\n",
      "‚ö†Ô∏è Duplicato PAIC87200Q: tengo PAIC87200Q-PTOF_2022_25_-_A.S._2024_25.pdf, scarto PAIC87200Q-PTOF 2022 25 - A.S. 2024 25.pdf\n",
      "‚úÖ TAIC80300X: I.C. \"L. Pirandello\"\n",
      "‚úÖ MBIC8AM00E: Ic Filippo De Pisis/Brugherio\n",
      "‚úÖ CTIS04300B: Marconi-Mangano\n",
      "‚ö†Ô∏è Duplicato CTIS04300B: tengo PTOF-Marconi-Mangano-2022-25.pdf, scarto CATANIA_CTIS04300B.pdf\n",
      "‚úÖ MIIC8DB00D: Ic Don Milani\n",
      "‚úÖ SVIC81300R: I. C. Varazze-Celle\n",
      "‚úÖ MOIC84800N: 10 I.C. Modena\n",
      "‚úÖ CSIS06700R: Iis S.Marco A. Itcg-Lc Ls Ipa Spezzano A\n",
      "üîé FGIC85400C_PTOF.pdf: codice estratto dal PDF ‚Üí FGIC85400C\n",
      "‚ö†Ô∏è FGIC85400C: Non in MIUR (procedo comunque)\n",
      "‚úÖ NATF130009: Iti L.Galvani-Giugliano-\n",
      "‚úÖ RMIC8C600P: Ic Anzio V\n",
      "‚úÖ RAIC82800B: I.C. 1 \"Andrea Canevaro\"\n",
      "‚úÖ BAIC818001: I.C. \"Massari Galilei\"\n",
      "‚ö†Ô∏è Duplicato BAIC818001: tengo BAIC818001-202225-202425-20250106.pdf, scarto BAIC818001_PTOF.pdf\n",
      "‚úÖ BOIS02700V: I.I.S. Crescenzi-Pacinotti-Sirani\n",
      "‚ö†Ô∏è Duplicato BOIS02700V: tengo PTOF_BOIS02700V_2022-25_aggiornamento_24-25.pdf, scarto PTOF BOIS02700V 2022-25 aggiornamento 24-25.pdf\n",
      "üîé PCPC00500A_PTOF.pdf: codice estratto dal PDF ‚Üí STRUTTURA5\n",
      "‚ö†Ô∏è PCPC00500A_PTOF.pdf: codici trovati ['PCPC00500A', 'STRUTTURA5', 'EFFICACIA8', 'EDUCATIVE9', 'CULTURALI9', 'LINGUAGGI1', 'FAMIGLIE28', 'DIDATTICA3', 'RECUPERO36', 'EDUCATION3', 'CONDOTTA40', 'PROFITTO44', 'PCSPD7500T'], scelto STRUTTURA5\n",
      "‚ö†Ô∏è STRUTTURA5: Non in MIUR (procedo comunque)\n",
      "‚úÖ SSIC80600X: D.A.Azuni - Budduso'\n",
      "‚úÖ MIIS08900V: G. Puecher - A. Olivetti\n",
      "‚úÖ BNIS02300V: Faicchio\n",
      "‚úÖ VEIC81400N: I.C. U. Foscolo Murano-Burano\n",
      "‚úÖ BAIS05300C: I.I.S.S. \"Luigi Russo\"\n",
      "‚úÖ FGIC85900G: I.C. \"Parisi-De Sanctis\"\n",
      "‚úÖ MITF19000B: Istituto Tecnico E Liceo - A. Steiner\n",
      "‚úÖ VTIC82500A: I.C. Capranica\n",
      "‚ö†Ô∏è Duplicato VTIC82500A: tengo VTIC82500A_G_NICOLINI.pdf, scarto CAPRANICA_VTIC82500A.pdf\n",
      "‚úÖ AGPC010001: Liceo Classico - Empedocle\n",
      "‚ö†Ô∏è Duplicato AGPC010001: tengo AGPC010001-202225-202425-20250604.pdf, scarto AGPC010001_PTOF.pdf\n",
      "‚ùå ELMAS_PTOF.pdf: Codice non estratto\n",
      "‚ö†Ô∏è CTIC823002: Non in MIUR (procedo comunque)\n",
      "‚ö†Ô∏è NAIC80800G: Non in MIUR (procedo comunque)\n",
      "‚úÖ KRIS00400C: Giuseppe Gangale\n",
      "‚úÖ VIPS08000D: L.S. \"Da Vinci\" Arzignano\n",
      "‚ö†Ô∏è Duplicato VIPS08000D: tengo VIPS08000D_LS_DA_VINCI_ARZIGNANO.pdf, scarto ARZIGNANO_VIPS08000D.pdf\n",
      "‚úÖ CRPC02000A: \"Daniele Manin\"\n",
      "‚úÖ MEIS03700V: I.I.S. \"A.M.Jaci - Caio Duilio\"\n",
      "‚ö†Ô∏è Duplicato MEIS03700V: tengo PTOF-MEIS03700V-2022-25.pdf, scarto MESSINA_MEIS03700V.pdf\n",
      "‚úÖ PVIS006008: Iis Alessandro Volta - Pavia\n",
      "‚úÖ RGIS01300V: Galileo Ferraris\n",
      "üîé BS1M004009_PTOF.pdf: codice estratto dal PDF ‚Üí BSPC12500Q\n",
      "‚ö†Ô∏è BS1M004009_PTOF.pdf: codici trovati ['BS1M004009', 'BSPC12500Q', 'BSPLLZ5006', 'BSPS06500N'], scelto BSPC12500Q\n",
      "‚úÖ BSPC12500Q: Liceo Classico Quadriennale Madonna Della Neve\n",
      "üîé AVEZZANO_AQPM01000G.pdf: codice estratto dal PDF ‚Üí AQPM01000G\n",
      "‚ö†Ô∏è AQPM01000G: Non in MIUR (procedo comunque)\n",
      "üîé BRUGHERIO_MIIC85700P.pdf: codice estratto dal PDF ‚Üí MBIC8AM00E\n",
      "‚ö†Ô∏è BRUGHERIO_MIIC85700P.pdf: codici trovati ['MIIC85700P', 'MBIC8AM00E'], scelto MBIC8AM00E\n",
      "‚úÖ MBIC8AM00E: Ic Filippo De Pisis/Brugherio\n",
      "‚ö†Ô∏è Duplicato MBIC8AM00E: tengo BRUGHERIO_MIIC85700P.pdf, scarto BRUGHERIO_MBIC8AM00E.pdf\n",
      "‚úÖ MIPMU4500Z: Liceo Delle Scienze Umane Opz. Economico Sociale S\n",
      "‚úÖ SOIC82100B: I.C. Sondrio - \"Paesi Orobici\"\n",
      "‚úÖ ISIS003002: Istituto Omnicomprensivo \"A. Giordano\"\n",
      "‚ùå PTOF_TADDIA_2019-2022_.pdf: Codice non estratto\n",
      "‚úÖ MOIC84900D: 2 I.C. Ravarino\n",
      "‚ö†Ô∏è Duplicato MOIC84900D: tengo MOIC84900D-202225-202425-20250115.pdf, scarto MOIC84900D_PTOF.pdf\n",
      "‚úÖ BORC10500R: Istituto Salesiano Beata Vergine Di San Luca\n",
      "‚ö†Ô∏è Duplicato BORC10500R: tengo BORC10500R_BEATA_VERGINE_DI_SAN_LUCA.pdf, scarto BOLOGNA_BORC10500R.pdf\n",
      "‚úÖ ROIS012001: I.I.S. \"Viola-Marchesini\" Rovigo\n",
      "‚úÖ FEIS01400G: Ist.Istruzione Superiore \"F.Lli Taddia\"\n",
      "‚úÖ CRIC817004: I.C. Spino D'Adda \"L. Chiesa\"\n",
      "‚úÖ SSPS05000G: Liceo Scientifico Statale Lorenzo Mossa\n",
      "üîé PTOF 2024-25.pdf: codice estratto dal PDF ‚Üí NAPS36000R\n",
      "‚úÖ NAPS36000R: L.Scient.\"Carlo Urbani\"San Giorgio A Cr.\n",
      "‚ö†Ô∏è Duplicato NAPS36000R: tengo PTOF_2024-25.pdf, scarto PTOF 2024-25.pdf\n",
      "\n",
      "üìã PDF riconosciuti: 111\n",
      "üìã PDF da processare (deduplicati): 96\n",
      "\n",
      "======================================================================\n",
      "üìù STEP 1: Conversione PDF ‚Üí Markdown\n",
      "======================================================================\n",
      "üîÑ Convertendo: PTOF_RMIS02400L-2025-2028_def.pdf ‚Üí RMIS02400L_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF_2024-25.pdf ‚Üí NAPS36000R_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CEIC87400L_PTOF.pdf ‚Üí CEIC87400L_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: AGPC010001-202225-202425-20250604.pdf ‚Üí AGPC010001_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF-Marconi-Mangano-2022-25.pdf ‚Üí CTIS04300B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MOIC84900D-202225-202425-20250115.pdf ‚Üí MOIC84900D_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BAIC89400E_PTOF.pdf ‚Üí BAIC89400E_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: VTIC82500A_G_NICOLINI.pdf ‚Üí VTIC82500A_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PATDEE500L_PTOF.pdf ‚Üí PATDEE500L_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: RMIS01600N_PTOF.pdf ‚Üí RMIS01600N_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PEIS00300X_PTOF.pdf ‚Üí PEIS00300X_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CAGLIARI_CAIC86800V.pdf ‚Üí CAIC8AM00E_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BNIS01100L_PTOF.pdf ‚Üí LEPC13000N_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: Aggiornamento-PTOF-2023-24-RMIC8GA002-202225-202324-20231204.pdf ‚Üí RMIC8GA002_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: TOPS10000T_PTOF.pdf ‚Üí TOPS10000T_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: TRABIA_PAIC888009.pdf ‚Üí PAIC888009_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MSIC81200D-202225-202425-20250626.pdf ‚Üí MSIC81200D_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF-MIRFHT500U-202225-rev.-2024-25.pdf ‚Üí MIRFHT500U_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PAPS3Q5009-202528-202425-20250120.pdf ‚Üí PAPS3Q5009_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: SAN_SECONDO_PARMENSE_PRIS00200Q.pdf ‚Üí PRIS00200Q_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF_2025-28_scelte_strategiche.pdf ‚Üí TRMM045005_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF_BOIS02700V_2022-25_aggiornamento_24-25.pdf ‚Üí BOIS02700V_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: NARH105008_PTOF.pdf ‚Üí NARH105008_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CSIC80800Q_PTOF.pdf ‚Üí VE1M6Q5004_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PALERMO_PAPC030004.pdf ‚Üí PAPC030004_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: AQIS01800Q-202225-202425-20241222.pdf ‚Üí AQIS01800Q_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: LEIC887006-202528-202425-20250122.pdf ‚Üí LEIC887006_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: VEROLI_FRPC02500X.pdf ‚Üí FRPC02500X_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: SRTL49500I_PTOF.pdf ‚Üí SRTL49500I_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF_2025-28-a.s.-24-25_Timbro.pdf ‚Üí PZIS029003_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: RMPL355003_PTOF.pdf ‚Üí RMPL355003_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: UD1M00600L_PTOF.pdf ‚Üí UD1M00600L_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BG1M02700A_PTOF.pdf ‚Üí BG1M02700A_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF 22-25_Aggiornamento 24-25_RMIS09400V.pdf ‚Üí RMIS09400V_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: TORINO_TOIC8A100T.pdf ‚Üí TOIC8A100T_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: VIPS08000D_LS_DA_VINCI_ARZIGNANO.pdf ‚Üí VIPS08000D_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MATERA_MTIS009001.pdf ‚Üí MTIS009001_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF-MEIS03700V-2022-25.pdf ‚Üí MEIS03700V_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PAIC87200Q-PTOF_2022_25_-_A.S._2024_25.pdf ‚Üí PAIC87200Q_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: TARANTO_TAIC829004.pdf ‚Üí TAIC829004_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: VR1A23500E_PTOF.pdf ‚Üí VR1A23500E_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CARLENTINI_SRIC823006.pdf ‚Üí SRIC823006_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: FOGGIA_FGIC86200B.pdf ‚Üí FGIC86200B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CHIC80700E_PTOF.pdf ‚Üí CHIC80700E_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF-2025-2028-3.pdf ‚Üí RMIC8FA00B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BGPS02000G_PTOF.pdf ‚Üí BGPS02000G_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CANICATT√É≈í_AGIS00100X.pdf ‚Üí AGIS00100X_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028.pdf ‚Üí ME1A14100N_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF-TRIENNIO-2025-2028.pdf ‚Üí NASD04000B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: GENOVA_GEIS01400Q.pdf ‚Üí GEIS01400Q_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MOIS00200C_PTOF.pdf ‚Üí MOIS00200C_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: LANCIANO_CHIS019001.pdf ‚Üí CHIS019001_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: SOPS050001_PTOF.pdf ‚Üí SOPS050001_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MTIS01200R_PTOF.pdf ‚Üí MTIS01200R_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CNIS01100D-202225-202425-20250117.pdf ‚Üí CNIS01100D_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MIPC09500C_PTOF.pdf ‚Üí MIPC09500C_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BAIC818001-202225-202425-20250106.pdf ‚Üí BAIC818001_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BORC10500R_BEATA_VERGINE_DI_SAN_LUCA.pdf ‚Üí BORC10500R_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PTOF-completo-25-28.pdf ‚Üí GERI015006_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: TEIS012009_PTOF.pdf ‚Üí TEIS012009_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: AVERSA_CEPS02000T.pdf ‚Üí CEPS02000T_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: VAPLVL5003_PTOF.pdf ‚Üí VAPLVL5003_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MIIC836006_PTOF.pdf ‚Üí MIIC836006_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: TARANTO_TAIC80300X.pdf ‚Üí TAIC80300X_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BRUGHERIO_MIIC85700P.pdf ‚Üí MBIC8AM00E_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MIIC8DB00D_PTOF.pdf ‚Üí MIIC8DB00D_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: SVIC81300R_PTOF.pdf ‚Üí SVIC81300R_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MOIC84800N_PTOF.pdf ‚Üí MOIC84800N_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: SAN_MARCO_ARGENTANO_CSIS06700R.pdf ‚Üí CSIS06700R_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: FGIC85400C_PTOF.pdf ‚Üí FGIC85400C_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: NATF130009_PTOF.pdf ‚Üí NATF130009_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: RMIC8C600P_PTOF.pdf ‚Üí RMIC8C600P_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: RAIC82800B_PTOF.pdf ‚Üí RAIC82800B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PCPC00500A_PTOF.pdf ‚Üí STRUTTURA5_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BUDDUSO_SSIC80600X.pdf ‚Üí SSIC80600X_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: RHO_MIIS08900V.pdf ‚Üí MIIS08900V_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BNIS02300V_PTOF.pdf ‚Üí BNIS02300V_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: VENEZIA_VEIC81400N.pdf ‚Üí VEIC81400N_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BAIS05300C_PTOF.pdf ‚Üí BAIS05300C_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: FOGGIA_FGIC85900G.pdf ‚Üí FGIC85900G_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MILANO_MITF19000B.pdf ‚Üí MITF19000B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CALTAGIRONE_CTIC823002.pdf ‚Üí CTIC823002_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: NAIC80800G_PTOF.pdf ‚Üí NAIC80800G_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: KRIS00400C_PTOF.pdf ‚Üí KRIS00400C_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CRPC02000A_PTOF.pdf ‚Üí CRPC02000A_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: PAVIA_PVIS006008.pdf ‚Üí PVIS006008_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: RAGUSA_RGIS01300V.pdf ‚Üí RGIS01300V_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BS1M004009_PTOF.pdf ‚Üí BSPC12500Q_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: AVEZZANO_AQPM01000G.pdf ‚Üí AQPM01000G_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: MIPMU4500Z-201922-201819-20190131.pdf ‚Üí MIPMU4500Z_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: SOIC82100B_PTOF.pdf ‚Üí SOIC82100B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: ISIS003002_PTOF.pdf ‚Üí ISIS003002_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: ROVIGO_ROIS012001.pdf ‚Üí ROIS012001_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CENTO_FEIS01400G.pdf ‚Üí FEIS01400G_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: CRIC817004_PTOF.pdf ‚Üí CRIC817004_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: SSPS05000G_PTOF.pdf ‚Üí SSPS05000G_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "\n",
      "üìä Convertiti: 96 file\n",
      "\n",
      "======================================================================\n",
      "ü§ñ STEP 2: Analisi Multi-Agente\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:29:12,903 - INFO - Loaded pipeline config from /Users/danieledragoni/git/LIste/config/pipeline_config.json\n",
      "2025-12-23 14:29:14,990 - INFO - Loaded SchoolDatabase with 61855 schools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Analizzando: RMIS02400L\n",
      "   Processing RMIS02400L...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:29:15,014 - INFO - [Pipeline] Long document (173513 chars) - using chunked analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Long doc (173k chars) - chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:29:15,023 - INFO - [Pipeline] Split into 5 chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Analyst: Chunk 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:29:15,024 - INFO - [gemma3:27b] Drafting chunk 1/5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Analyst: Chunk 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:29:51,110 - INFO - [gemma3:27b] Drafting chunk 2/5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Analyst: Chunk 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:30:36,564 - INFO - [gemma3:27b] Drafting chunk 3/5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Analyst: Chunk 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:31:21,125 - INFO - [gemma3:27b] Drafting chunk 4/5...\n"
     ]
    }
   ],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# COMPLETO ANALISI PTOF (VERSIONE SEMPLIFICATA)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# üöÄ PDF ‚Üí MD ‚Üí Analisi Multi-Agente ‚Üí JSON (arricchito) ‚Üí rebuild_csv ‚Üí CSV\n",
    "# ‚úÖ Catena dati: Normalizzazioni nel JSON, CSV √® derivato (solo lettura)\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import logging\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configurazione\n",
    "BASE_DIR = Path('/Users/danieledragoni/git/LIste')\n",
    "os.chdir(BASE_DIR)\n",
    "sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "INBOX_DIR = BASE_DIR / \"ptof_inbox\"\n",
    "PROCESSED_DIR = BASE_DIR / \"ptof_processed\"\n",
    "MD_DIR = BASE_DIR / \"ptof_md\"\n",
    "ANALYSIS_DIR = BASE_DIR / \"analysis_results\"\n",
    "CSV_FILE = BASE_DIR / \"data\" / \"analysis_summary.csv\"\n",
    "\n",
    "# Crea directory\n",
    "for d in [INBOX_DIR, PROCESSED_DIR, MD_DIR, ANALYSIS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70, flush=True)\n",
    "print(\"üöÄ WORKFLOW COMPLETO ANALISI PTOF\", flush=True)\n",
    "print(f\"üïê {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", flush=True)\n",
    "print(\"=\"*70, flush=True)\n",
    "\n",
    "# =====================================================\n",
    "# INIZIALIZZAZIONE DATABASE MIUR\n",
    "# =====================================================\n",
    "print(\"\\nüîß Caricamento database...\", flush=True)\n",
    "\n",
    "import src.utils.school_database as school_db_module\n",
    "importlib.reload(school_db_module)\n",
    "from src.utils.school_database import SchoolDatabase\n",
    "\n",
    "SchoolDatabase._instance = None\n",
    "SchoolDatabase._loaded = False\n",
    "SCHOOL_DB = SchoolDatabase()\n",
    "print(f\"   ‚úÖ Database MIUR: {len(SCHOOL_DB._data)} scuole\", flush=True)\n",
    "\n",
    "# Conta PDF\n",
    "inbox_pdfs = list(INBOX_DIR.glob(\"*.pdf\"))\n",
    "print(f\"\\nüì• PDF in inbox: {len(inbox_pdfs)}\", flush=True)\n",
    "\n",
    "if not inbox_pdfs:\n",
    "    print(\"‚ö†Ô∏è Nessun PDF da processare!\", flush=True)\n",
    "    print(\"üí° Copia i PDF in ptof_inbox/ e riprova\", flush=True)\n",
    "else:\n",
    "    # =====================================================\n",
    "    # STEP 0: VALIDAZIONE PRE-ANALISI\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üîç STEP 0: Validazione codici meccanografici\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    recognized_pdfs = []\n",
    "    process_pdfs = {}\n",
    "    already_analyzed = set()\n",
    "    code_pattern = re.compile(r'([A-Z]{2}[A-Z0-9]{2}[A-Z0-9]{6})', re.IGNORECASE)\n",
    "    \n",
    "    def extract_text_from_pdf(pdf_path, max_pages=4, max_chars=20000):\n",
    "        text_parts = []\n",
    "        total_chars = 0\n",
    "        try:\n",
    "            from pypdf import PdfReader\n",
    "            reader = PdfReader(str(pdf_path))\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                if i >= max_pages:\n",
    "                    break\n",
    "                try:\n",
    "                    page_text = page.extract_text() or \"\"\n",
    "                except Exception:\n",
    "                    continue\n",
    "                text_parts.append(page_text)\n",
    "                total_chars += len(page_text)\n",
    "                if total_chars >= max_chars:\n",
    "                    break\n",
    "            return \"\\n\".join(text_parts).strip()\n",
    "        except Exception:\n",
    "            try:\n",
    "                import fitz\n",
    "                doc = fitz.open(str(pdf_path))\n",
    "                for i in range(min(max_pages, len(doc))):\n",
    "                    page_text = doc[i].get_text(\"text\") or \"\"\n",
    "                    text_parts.append(page_text)\n",
    "                    total_chars += len(page_text)\n",
    "                    if total_chars >= max_chars:\n",
    "                        break\n",
    "                return \"\\n\".join(text_parts).strip()\n",
    "            except Exception:\n",
    "                return \"\"\n",
    "\n",
    "    def extract_school_code(name, school_db, pdf_path=None):\n",
    "        def dedupe(candidates):\n",
    "            seen = set()\n",
    "            unique = []\n",
    "            for code in candidates:\n",
    "                if code in seen:\n",
    "                    continue\n",
    "                seen.add(code)\n",
    "                unique.append(code)\n",
    "            return unique\n",
    "\n",
    "        def pick_valid(candidates):\n",
    "            if not school_db:\n",
    "                return None, None\n",
    "            for code in candidates:\n",
    "                miur_data = school_db.get_school_data(code)\n",
    "                if miur_data:\n",
    "                    return code, miur_data\n",
    "            return None, None\n",
    "\n",
    "        filename_candidates = code_pattern.findall(name.upper())\n",
    "        filename_candidates = [c for c in filename_candidates if any(ch.isdigit() for ch in c)]\n",
    "        filename_candidates = dedupe(filename_candidates)\n",
    "\n",
    "        code, miur_data = pick_valid(filename_candidates)\n",
    "        if code:\n",
    "            return code, filename_candidates, miur_data, \"filename\"\n",
    "\n",
    "        pdf_candidates = []\n",
    "        if pdf_path is not None:\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            if text:\n",
    "                pdf_candidates = code_pattern.findall(text.upper())\n",
    "                pdf_candidates = [c for c in pdf_candidates if any(ch.isdigit() for ch in c)]\n",
    "                pdf_candidates = dedupe(pdf_candidates)\n",
    "                code, miur_data = pick_valid(pdf_candidates)\n",
    "                if code:\n",
    "                    combined = filename_candidates + [c for c in pdf_candidates if c not in filename_candidates]\n",
    "                    return code, combined, miur_data, \"pdf\"\n",
    "\n",
    "        combined = filename_candidates + [c for c in pdf_candidates if c not in filename_candidates]\n",
    "        if pdf_candidates:\n",
    "            return pdf_candidates[0], combined, None, \"pdf\"\n",
    "        if filename_candidates:\n",
    "            return filename_candidates[0], combined, None, \"filename\"\n",
    "        return None, [], None, None\n",
    "\n",
    "    def json_status(path):\n",
    "        if not path.exists():\n",
    "            return 'missing'\n",
    "        if path.stat().st_size == 0:\n",
    "            return 'empty'\n",
    "        try:\n",
    "            json.loads(path.read_text())\n",
    "        except Exception:\n",
    "            return 'invalid'\n",
    "        return 'valid'\n",
    "    \n",
    "    def get_analysis_status(school_code):\n",
    "        candidates = [\n",
    "            ANALYSIS_DIR / f\"{school_code}_PTOF_analysis.json\",\n",
    "            ANALYSIS_DIR / f\"{school_code}_analysis.json\",\n",
    "        ]\n",
    "        statuses = [(path, json_status(path)) for path in candidates]\n",
    "        for path, status in statuses:\n",
    "            if status == 'valid':\n",
    "                return path, status\n",
    "        for path, status in statuses:\n",
    "            if status in ('empty', 'invalid'):\n",
    "                return path, status\n",
    "        return candidates[0], 'missing'\n",
    "\n",
    "    def choose_preferred_pdf(current_path, new_path):\n",
    "        current_stat = current_path.stat()\n",
    "        new_stat = new_path.stat()\n",
    "        if new_stat.st_mtime != current_stat.st_mtime:\n",
    "            return new_path if new_stat.st_mtime > current_stat.st_mtime else current_path\n",
    "        if new_stat.st_size != current_stat.st_size:\n",
    "            return new_path if new_stat.st_size > current_stat.st_size else current_path\n",
    "        return current_path\n",
    "    \n",
    "    for pdf_path in inbox_pdfs:\n",
    "        school_code, candidates, miur_data, source = extract_school_code(pdf_path.stem, SCHOOL_DB, pdf_path)\n",
    "        if not school_code:\n",
    "            print(f\"‚ùå {pdf_path.name}: Codice non estratto\", flush=True)\n",
    "            continue\n",
    "        if source == 'pdf':\n",
    "            print(f\"üîé {pdf_path.name}: codice estratto dal PDF ‚Üí {school_code}\", flush=True)\n",
    "        if len(candidates) > 1:\n",
    "            print(f\"‚ö†Ô∏è {pdf_path.name}: codici trovati {candidates}, scelto {school_code}\", flush=True)\n",
    "        \n",
    "        if miur_data:\n",
    "            print(f\"‚úÖ {school_code}: {miur_data.get('denominazione', 'ND')[:50]}\", flush=True)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {school_code}: Non in MIUR (procedo comunque)\", flush=True)\n",
    "        \n",
    "        recognized_pdfs.append((pdf_path, school_code, miur_data))\n",
    "        \n",
    "        analysis_path, status = get_analysis_status(school_code)\n",
    "\n",
    "        if status == 'valid':\n",
    "            if school_code not in already_analyzed:\n",
    "                print(f\"‚è≠Ô∏è {school_code}: Analisi gi√† presente ({analysis_path.name})\", flush=True)\n",
    "                already_analyzed.add(school_code)\n",
    "            continue\n",
    "        if status == 'empty':\n",
    "            print(f\"‚ö†Ô∏è {school_code}: JSON vuoto, rieseguo analisi\", flush=True)\n",
    "        elif status == 'invalid':\n",
    "            print(f\"‚ö†Ô∏è {school_code}: JSON non valido, rieseguo analisi\", flush=True)\n",
    "        \n",
    "        if school_code in process_pdfs:\n",
    "            kept = choose_preferred_pdf(process_pdfs[school_code][0], pdf_path)\n",
    "            if kept == pdf_path:\n",
    "                print(f\"‚ö†Ô∏è Duplicato {school_code}: tengo {pdf_path.name}, scarto {process_pdfs[school_code][0].name}\", flush=True)\n",
    "                process_pdfs[school_code] = (pdf_path, school_code, miur_data)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Duplicato {school_code}: tengo {process_pdfs[school_code][0].name}, scarto {pdf_path.name}\", flush=True)\n",
    "            continue\n",
    "        \n",
    "        process_pdfs[school_code] = (pdf_path, school_code, miur_data)\n",
    "    \n",
    "    process_pdfs = list(process_pdfs.values())\n",
    "    print(f\"\\nüìã PDF riconosciuti: {len(recognized_pdfs)}\", flush=True)\n",
    "    print(f\"üìã PDF da processare (deduplicati): {len(process_pdfs)}\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # STEP 1: CONVERSIONE PDF ‚Üí MARKDOWN\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üìù STEP 1: Conversione PDF ‚Üí Markdown\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    from src.processing.convert_pdfs_to_md import pdf_to_markdown\n",
    "    \n",
    "    converted = []\n",
    "    \n",
    "    for pdf_path, school_code, miur_data in process_pdfs:\n",
    "        md_output = MD_DIR / f\"{school_code}_ptof.md\"\n",
    "        \n",
    "        # Verifica se gi√† analizzato\n",
    "        analysis_path, status = get_analysis_status(school_code)\n",
    "        if status == 'valid':\n",
    "            print(f\"‚è≠Ô∏è Gi√† analizzato: {school_code} ({analysis_path.name})\", flush=True)\n",
    "            continue\n",
    "        \n",
    "        print(f\"üîÑ Convertendo: {pdf_path.name} ‚Üí {school_code}_ptof.md\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            if pdf_to_markdown(str(pdf_path), str(md_output)):\n",
    "                converted.append((pdf_path, school_code, miur_data))\n",
    "                print(f\"   ‚úÖ Convertito!\", flush=True)\n",
    "            else:\n",
    "                print(f\"   ‚ùå Errore conversione\", flush=True)\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Errore: {e}\", flush=True)\n",
    "    \n",
    "    print(f\"\\nüìä Convertiti: {len(converted)} file\", flush=True)\n",
    "    \n",
    "    if converted:\n",
    "        # =====================================================\n",
    "        # STEP 2: ANALISI MULTI-AGENTE\n",
    "        # =====================================================\n",
    "        print(\"\\n\" + \"=\"*70, flush=True)\n",
    "        print(\"ü§ñ STEP 2: Analisi Multi-Agente\", flush=True)\n",
    "        print(\"=\"*70, flush=True)\n",
    "        \n",
    "        # Forza reload del modulo pipeline\n",
    "        import app.agentic_pipeline as agentic_module\n",
    "        importlib.reload(agentic_module)\n",
    "        from app.agentic_pipeline import (\n",
    "            AnalystAgent, RefinerAgent, ReviewerAgent, SynthesizerAgent,\n",
    "            process_single_ptof\n",
    "        )\n",
    "        \n",
    "        analyst = AnalystAgent()\n",
    "        refiner = RefinerAgent()\n",
    "        reviewer = ReviewerAgent()\n",
    "        synthesizer = SynthesizerAgent()\n",
    "        \n",
    "        analyzed = []\n",
    "        \n",
    "        for pdf_path, school_code, miur_data in converted:\n",
    "            md_file = MD_DIR / f\"{school_code}_ptof.md\"\n",
    "            \n",
    "            if not md_file.exists():\n",
    "                print(f\"‚ö†Ô∏è MD non trovato: {school_code}\", flush=True)\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nüìù Analizzando: {school_code}\", flush=True)\n",
    "            \n",
    "            try:\n",
    "                def status_cb(msg):\n",
    "                    print(f\"   {msg}\", flush=True)\n",
    "                \n",
    "                # process_single_ptof salva JSON gi√† arricchito (con enrich_json_metadata)\n",
    "                result = process_single_ptof(\n",
    "                    str(md_file),\n",
    "                    analyst,\n",
    "                    reviewer,\n",
    "                    refiner,\n",
    "                    synthesizer,\n",
    "                    str(ANALYSIS_DIR),\n",
    "                    status_callback=status_cb\n",
    "                )\n",
    "                \n",
    "                if result:\n",
    "                    analyzed.append(school_code)\n",
    "                    # Leggi metadati dal JSON salvato per feedback\n",
    "                    json_path = ANALYSIS_DIR / f\"{school_code}_PTOF_analysis.json\"\n",
    "                    with open(json_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    md_path = ANALYSIS_DIR / f\"{school_code}_PTOF_analysis.md\"\n",
    "                    if not md_path.exists() or md_path.stat().st_size == 0:\n",
    "                        try:\n",
    "                            md_path.write_text(json.dumps(data, ensure_ascii=False, indent=2))\n",
    "                            print(\"   INFO: MD vuoto, scritto JSON di fallback\", flush=True)\n",
    "                        except Exception as e:\n",
    "                            print(f\"   WARN: Impossibile ricreare MD: {e}\", flush=True)\n",
    "                    meta = data.get('metadata', {})\n",
    "                    print(f\"   ‚úÖ Salvato - {meta.get('provincia', 'ND')}, {meta.get('regione', 'ND')}\", flush=True)\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è Nessun risultato\", flush=True)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Errore analisi: {e}\", flush=True)\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        print(f\"\\nüìä Analizzati: {len(analyzed)} file\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # STEP 3: REBUILD CSV DA JSON\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üìä STEP 3: Rebuild CSV da JSON\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    # Esegui rebuild_csv_clean.py\n",
    "    result = subprocess.run(\n",
    "        ['python3', 'src/processing/rebuild_csv_clean.py'],\n",
    "        capture_output=True, text=True, cwd=str(BASE_DIR)\n",
    "    )\n",
    "    print(result.stdout, flush=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"‚ö†Ô∏è Errore: {result.stderr}\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # STEP 4: VERIFICA CSV FINALE\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üìä STEP 4: Verifica CSV\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    if CSV_FILE.exists():\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(CSV_FILE)\n",
    "        print(f\"üìä CSV contiene {len(df)} scuole\", flush=True)\n",
    "        print(f\"\\nColonne principali:\", flush=True)\n",
    "        print(df[['school_id', 'denominazione', 'provincia', 'regione', 'area_geografica', 'ptof_orientamento_maturity_index']].to_string(), flush=True)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è CSV non ancora creato\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # STEP 5: SPOSTA PDF PROCESSATI\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üì¶ STEP 5: Organizzazione file processati\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    batch_dir = PROCESSED_DIR / f\"batch_{timestamp}\"\n",
    "    batch_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    processed_count = 0\n",
    "    for pdf_path, school_code, _ in recognized_pdfs:\n",
    "        analysis_path, status = get_analysis_status(school_code)\n",
    "        if status == 'valid':\n",
    "            dest = batch_dir / pdf_path.name\n",
    "            shutil.move(str(pdf_path), str(dest))\n",
    "            processed_count += 1\n",
    "            print(f\"üì¶ Spostato: {pdf_path.name}\", flush=True)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Analisi non valida ({analysis_path.name}), non sposto: {pdf_path.name}\", flush=True)\n",
    "    \n",
    "    print(f\"\\nüìä PDF spostati in batch: {processed_count}\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # RIEPILOGO FINALE\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üìä RIEPILOGO FINALE\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    final_count = len(list(ANALYSIS_DIR.glob(\"*_analysis.json\")))\n",
    "    print(f\"üìÅ Totale analisi JSON: {final_count}\", flush=True)\n",
    "    print(f\"üìä CSV generato: {CSV_FILE}\", flush=True)\n",
    "    print(f\"\\nüí° Catena dati:\", flush=True)\n",
    "    print(f\"   JSON (verit√†) ‚Üí rebuild_csv_clean.py ‚Üí CSV (derivato)\", flush=True)\n",
    "    print(f\"\\nüöÄ Avvia dashboard: streamlit run app/Home.py\", flush=True)\n",
    "    print(\"=\"*70, flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
