{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Comandi Make Utili\n",
    "\n",
    "Il progetto include un `Makefile` per semplificare le operazioni comuni. Ecco alcune combinazioni utili:\n",
    "\n",
    "- **`make refresh`**: Rigenera il CSV dai JSON esistenti e avvia immediatamente la dashboard. Utile se hai modificato manualmente dei JSON o se vuoi vedere subito i cambiamenti senza rieseguire l'analisi.\n",
    "- **`make full`**: Esegue l'intero ciclo: analisi dei PDF (`run`), rigenerazione del CSV (`csv`) e avvio della dashboard (`dashboard`).\n",
    "- **`make backfill`**: Esegue uno script specifico per recuperare metadati mancanti usando un LLM.\n",
    "\n",
    "Per vedere tutti i comandi disponibili, esegui `make help` nel terminale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Guida al Workflow di Analisi PTOF\n",
    "\n",
    "Questo notebook esegue l'intero processo di analisi dei PTOF (Piani Triennali dell'Offerta Formativa) utilizzando un'architettura multi-agente.\n",
    "\n",
    "## üîÑ Flusso di Lavoro\n",
    "\n",
    "1.  **Input**: I file PDF vengono letti dalla cartella `ptof_inbox/`.\n",
    "2.  **Conversione**: I PDF vengono convertiti in Markdown (`ptof_md/`) per essere leggibili dagli agenti AI.\n",
    "3.  **Analisi AI**: Una catena di agenti (Analyst, Refiner, Reviewer, Synthesizer) analizza il contenuto e produce un JSON strutturato (`analysis_results/`).\n",
    "4.  **Arricchimento**: I dati vengono arricchiti con metadati ufficiali (MIUR) e calcolati indici di maturit√†.\n",
    "5.  **Consolidamento**: Tutti i JSON vengono aggregati in un unico file CSV (`data/analysis_summary.csv`) che alimenta la Dashboard.\n",
    "6.  **Archiviazione**: I PDF processati con successo vengono spostati in `ptof_processed/`.\n",
    "\n",
    "## üìÇ File e Cartelle Coinvolti\n",
    "\n",
    "| Percorso | Descrizione |\n",
    "| :--- | :--- |\n",
    "| `ptof_inbox/` | **Input**: Copia qui i file PDF dei PTOF da analizzare. |\n",
    "| `ptof_md/` | **Intermedio**: Contiene le conversioni in testo Markdown dei PDF. |\n",
    "| `analysis_results/` | **Output JSON**: Contiene un file JSON per ogni scuola analizzata (Fonte di Verit√†). |\n",
    "| `data/analysis_summary.csv` | **Output CSV**: File riassuntivo generato dai JSON, usato dalla Dashboard. |\n",
    "| `ptof_processed/` | **Archivio**: Dove finiscono i PDF dopo essere stati analizzati. |\n",
    "| `src/processing/rebuild_csv_clean.py` | **Script**: Rigenera il CSV partendo dai JSON esistenti. |\n",
    "| `app/Home.py` | **Dashboard**: Applicazione Streamlit per visualizzare i dati. |\n",
    "\n",
    "## üöÄ Come Eseguire\n",
    "\n",
    "1.  Assicurati di aver copiato i PDF in `ptof_inbox/`.\n",
    "2.  Esegui la cella di codice sottostante.\n",
    "3.  Attendi il completamento di tutti gli step.\n",
    "4.  Avvia la dashboard con `streamlit run app/Home.py` (o usa il comando `make dashboard` da terminale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ WORKFLOW COMPLETO ANALISI PTOF\n",
      "üïê 2025-12-23 21:44:37\n",
      "======================================================================\n",
      "\n",
      "üîß Caricamento database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 21:44:38,863 - INFO - [SchoolDatabase] Loaded 61855 schools.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SchoolDatabase] Loaded 61855 schools from CSVs.\n",
      "   ‚úÖ Database MIUR: 61855 scuole\n",
      "\n",
      "üì• PDF in inbox: 233\n",
      "\n",
      "======================================================================\n",
      "üîç STEP 0: Validazione codici meccanografici\n",
      "======================================================================\n",
      "‚úÖ RMIS02400L: Istruzione Superiore Via Delle Scienze\n",
      "‚è≠Ô∏è RMIS02400L: Analisi gi√† presente (RMIS02400L_PTOF_analysis.json)\n",
      "‚ùå linee_di_indirizzo_del_DS_202210241729.pdf: Codice non estratto\n",
      "üîé PTOF_2024-25.pdf: codice estratto dal PDF ‚Üí NAPS36000R\n",
      "‚úÖ NAPS36000R: L.Scient.\"Carlo Urbani\"San Giorgio A Cr.\n",
      "‚è≠Ô∏è NAPS36000R: Analisi gi√† presente (NAPS36000R_PTOF_analysis.json)\n",
      "‚úÖ SATE06901B: Itas S.Caterina Da Siena Salerno\n",
      "‚úÖ CEIC87400L: I.C. Di San Marcellino\n",
      "‚è≠Ô∏è CEIC87400L: Analisi gi√† presente (CEIC87400L_PTOF_analysis.json)\n",
      "‚úÖ AREE82004B: \"G. Mazzini\"\n",
      "‚úÖ AGPC010001: Liceo Classico - Empedocle\n",
      "‚è≠Ô∏è AGPC010001: Analisi gi√† presente (AGPC010001_PTOF_analysis.json)\n",
      "‚úÖ RGAA809032: Trebalate\n",
      "üîé PTOF-Marconi-Mangano-2022-25.pdf: codice estratto dal PDF ‚Üí CTIS04300B\n",
      "‚ö†Ô∏è PTOF-Marconi-Mangano-2022-25.pdf: codici trovati ['CTIS04300B', 'CTTF04301X', 'CTTF043508', 'CTRF043014', 'CTRF04350C'], scelto CTIS04300B\n",
      "‚úÖ CTIS04300B: Marconi-Mangano\n",
      "‚è≠Ô∏è CTIS04300B: Analisi gi√† presente (CTIS04300B_PTOF_analysis.json)\n",
      "‚úÖ TPAA807022: Scuola Infanzia \"Montessori\"\n",
      "‚úÖ BAAA83103A: C.Da Trito\n",
      "‚úÖ MOIC84900D: 2 I.C. Ravarino\n",
      "‚è≠Ô∏è MOIC84900D: Analisi gi√† presente (MOIC84900D_PTOF_analysis.json)\n",
      "‚úÖ BAIC89400E: I.C. \"De Amicis-Giovanni Xxiii\"\n",
      "‚è≠Ô∏è BAIC89400E: Analisi gi√† presente (BAIC89400E_PTOF_analysis.json)\n",
      "‚úÖ NAAA8BW034: Plesso - D.Lorenzo Milani\n",
      "‚úÖ SRPS150012: Canicattini Bagni\n",
      "‚úÖ CSEE8AJ06X: Bisignano-Campo Sportivo\n",
      "‚úÖ TAEE80501N: Boschetti Alberti\n",
      "‚úÖ VTIC82500A: I.C. Capranica\n",
      "‚è≠Ô∏è VTIC82500A: Analisi gi√† presente (VTIC82500A_PTOF_analysis.json)\n",
      "‚úÖ PATDEE500L: Niccolo' Machiavelli\n",
      "‚è≠Ô∏è PATDEE500L: Analisi gi√† presente (PATDEE500L_PTOF_analysis.json)\n",
      "‚úÖ NAEE8G1015: Pomigliano 1 - Salvo D'Acquisto\n",
      "‚úÖ VAAA842018: Sc. Infanzia Mazzucchelli A. F.\n",
      "‚úÖ RMIS01600N: Via Delle Sette Chiese 259\n",
      "‚è≠Ô∏è RMIS01600N: Analisi gi√† presente (RMIS01600N_PTOF_analysis.json)\n",
      "‚úÖ AQPS019012: \"Enrico Fermi\"\n",
      "‚úÖ TPAA81501X: Plesso \"Nino Atria\"\n",
      "‚úÖ AVAA81003Q: Capoluogo-Castel Vetere Sul Cal\n",
      "‚úÖ PEIS00300X: Iis \"E.Alessandrini\" Montesilvano\n",
      "‚è≠Ô∏è PEIS00300X: Analisi gi√† presente (PEIS00300X_PTOF_analysis.json)\n",
      "üîé CAGLIARI_CAIC86800V.pdf: codice estratto dal PDF ‚Üí CAIC8AM00E\n",
      "‚ö†Ô∏è CAGLIARI_CAIC86800V.pdf: codici trovati ['CAIC86800V', 'CAIC8AM00E'], scelto CAIC8AM00E\n",
      "‚úÖ CAIC8AM00E: Ugo Foscolo - Via Stoccolma\n",
      "‚è≠Ô∏è CAIC8AM00E: Analisi gi√† presente (CAIC8AM00E_PTOF_analysis.json)\n",
      "üîé BNIS01100L_PTOF.pdf: codice estratto dal PDF ‚Üí LEPC13000N\n",
      "‚ö†Ô∏è BNIS01100L_PTOF.pdf: codici trovati ['BNIS01100L', 'LEPC13000N', 'LEPC130001'], scelto LEPC13000N\n",
      "‚úÖ LEPC13000N: Liceo \"Virgilio-Redi\"\n",
      "‚è≠Ô∏è LEPC13000N: Analisi gi√† presente (LEPC13000N_PTOF_analysis.json)\n",
      "‚úÖ LEMM84302E: G. Macchi Giurdignano\n",
      "‚úÖ FGAA85802N: Via Ponte Capo'\n",
      "‚úÖ RMIC8GA002: Ic Via P. Stabilini\n",
      "‚è≠Ô∏è RMIC8GA002: Analisi gi√† presente (RMIC8GA002_PTOF_analysis.json)\n",
      "‚úÖ BRMM82401B: Sms- A.Manzoni-S.Pancrazio\n",
      "‚úÖ SATD034011: Ite F.Besta Battipaglia\n",
      "‚úÖ PVIS01600V: Iis Galilei Voghera\n",
      "‚úÖ TOPS10000T: Charles Darwin\n",
      "‚è≠Ô∏è TOPS10000T: Analisi gi√† presente (TOPS10000T_PTOF_analysis.json)\n",
      "‚úÖ PAIC888009: Ic. Trabia -Giovanni Xxiii\n",
      "‚úÖ MSIC81200D: I.C. \"Massa 6\" Loc. Romagnano\n",
      "‚úÖ ALTF080003: Ascanio Sobrero\n",
      "‚úÖ MIRFHT500U: Barbara Melzi\n",
      "‚úÖ AVEE87401T: Capoluogo-Vallata\n",
      "‚úÖ PAPS3Q5009: Istituto Gonzaga\n",
      "‚úÖ PRIS00200Q: I.S.I.S.S. \"Galilei-Bocchialini\"\n",
      "‚úÖ TPTD00251R: Ist.Tec. Econ. -Perc. Ii Livello -Salemi\n",
      "‚úÖ AREE820018: \"G. Mameli\"\n",
      "‚úÖ COAA81301E: Como/Prestino\n",
      "‚úÖ RMMM856011: Cervi F.Lli\n",
      "üîé PTOF_2025-28_scelte_strategiche.pdf: codice estratto dal PDF ‚Üí TRMM045005\n",
      "‚úÖ TRMM045005: Terni \"L. Da Vinci E O. Nucula\"\n",
      "‚úÖ BOIS02700V: I.I.S. Crescenzi-Pacinotti-Sirani\n",
      "‚úÖ BAAA831029: C.Da S.Marco\n",
      "‚úÖ LTIC846006: I. C. \"Emma Castelnuovo\"\n",
      "‚úÖ NARH105008: Maria Montessori\n",
      "‚úÖ BGPS01301D: \"David Maria Turoldo\"\n",
      "üîé CSIC80800Q_PTOF.pdf: codice estratto dal PDF ‚Üí VE1M6Q5004\n",
      "‚ö†Ô∏è CSIC80800Q_PTOF.pdf: codici trovati ['CSIC80800Q', 'VE1M6Q5004'], scelto VE1M6Q5004\n",
      "‚úÖ VE1M6Q5004: Santa Caterina Da Siena\n",
      "‚úÖ PAPC030004: Meli\n",
      "‚úÖ AQIS01800Q: I.I.S \"A. Bafile\"\n",
      "‚úÖ LEIC887006: I.C. Galatina Polo 1\n",
      "‚úÖ TPTD00801A: Tecnico- A.F.M.Amm. Finanza E Marketing\n",
      "‚úÖ FRPC02500X: S.Bernardo\n",
      "‚úÖ SRTL49500I: Istituto Paritario \"S. Quasimodo\"\n",
      "‚úÖ CLTD01651N: Corso Serale A.F.M. - C.A.T. - Mussomeli\n",
      "‚úÖ NOSL010001: Liceo Artistico \"Felice Casorati\"\n",
      "üîé PTOF_2025-28-a.s.-24-25_Timbro.pdf: codice estratto dal PDF ‚Üí PZIS029003\n",
      "‚úÖ PZIS029003: I.O. \"E. Majorana\" Genzano Di Lucania\n",
      "‚úÖ RMPL355003: L.Ling. Mons. Tozzi\n",
      "‚úÖ UD1M00600L: Scuola Secondaria I Grado Paritaria G. Bearzi\n",
      "‚úÖ BG1M02700A: Scuola Sec. 1¬∞ Grado \"Sacro Cuore\"\n",
      "‚úÖ RMIS09400V: Pacinotti - Archimede\n",
      "‚úÖ BAEE027053: \"Duca D'Aosta\" 27 C.D. - Palese\n",
      "‚úÖ FREE830013: Supino Primaria\n",
      "‚úÖ TOIC8A100T: I.C. Vittorino Da Feltre - To\n",
      "‚úÖ TPTD00802B: Tecnico Turismo - Itc \"P. Mattarella\"\n",
      "‚úÖ PZMM88301L: I Grado \"A.Busciolano\" Pz\n",
      "‚úÖ BNTD022019: Cerreto Sannita\n",
      "‚úÖ LOTF003017: A.Cesaris\n",
      "‚úÖ PZTF02202T: I.T.T. \"Einst.-De Lor.\" Sez.Itis Potenza\n",
      "‚ùå PTOF iniziale 25_28.pdf: Codice non estratto\n",
      "‚úÖ VIPS08000D: L.S. \"Da Vinci\" Arzignano\n",
      "üîé MATERA_MTIS009001.pdf: codice estratto dal PDF ‚Üí MTIS009001\n",
      "‚ö†Ô∏è MATERA_MTIS009001.pdf: codici trovati ['MTIS009001', 'ELLALEGGE2', 'AGOSTO2019', 'IANOCOMEL2'], scelto MTIS009001\n",
      "‚ö†Ô∏è MTIS009001: Non in MIUR (procedo comunque)\n",
      "‚úÖ MEIS03700V: I.I.S. \"A.M.Jaci - Caio Duilio\"\n",
      "‚úÖ CBAA82709C: Scuola Dell'Infanzia Di Limosano\n",
      "‚úÖ PAIC87200Q: I.C. Padre Puglisi - Orestano\n",
      "‚úÖ RCAA84801P: Laureana B.Bellantone V.Sardegn\n",
      "‚úÖ TAIC829004: I.C. \"G. Salvemini\"\n",
      "‚úÖ FREE82003E: S.Donato V.C. Capoluogo\n",
      "‚úÖ VR1A23500E: Scuola Materna A.Provolo-Centro Infanzia\n",
      "‚úÖ SRIC823006: I I.C. \"Pirandello\" Carlentini\n",
      "‚úÖ BSPS00601V: (Sez. Ass. I.S. \"Carlo Beretta\")\n",
      "‚úÖ RMIS02400L: Istruzione Superiore Via Delle Scienze\n",
      "‚úÖ FGIC86200B: I.C. \"G. Catalano - Moscati\"\n",
      "‚ùå PTOF-2022-25-.pdf: Codice non estratto\n",
      "‚úÖ TATE04201C: P.Ssa Maria Pia\n",
      "‚úÖ LEEE86401G: Don Bosco\n",
      "‚úÖ BRAA81004C: Via Ofanto\n",
      "‚úÖ LTRA01650V: Ipa San Benedetto Serale\n",
      "üîé PTOF 2025-28 scelte strategiche.pdf: codice estratto dal PDF ‚Üí TRMM045005\n",
      "‚úÖ TRMM045005: Terni \"L. Da Vinci E O. Nucula\"\n",
      "‚ö†Ô∏è Duplicato TRMM045005: tengo PTOF_2025-28_scelte_strategiche.pdf, scarto PTOF 2025-28 scelte strategiche.pdf\n",
      "‚úÖ CHIC80700E: I.C. Fossacesia \"P.D.Pollidori\"\n",
      "‚úÖ SSAA813032: Scuola Dell'Infanzia\n",
      "‚úÖ AVEE81805N: Nicola Maria Abate\n",
      "üîé PTOF-2025-2028-3.pdf: codice estratto dal PDF ‚Üí RMIC8FA00B\n",
      "‚úÖ RMIC8FA00B: Ic Via Casale Del Finocchio\n",
      "‚úÖ RMMM8F9013: Andrea Velletrano\n",
      "‚úÖ BRMM07900G: Iss_Cpia Br\"Anna Lorenzetto\"\n",
      "‚úÖ PEAA822012: Loreto Aprutino - Cappuccini\n",
      "‚úÖ BGPS02000G: \"Filippo Lussana\"\n",
      "‚úÖ AGPM02101L: Im Francesco Crispi\n",
      "‚úÖ LETL04201D: I.T.G. \"G. Galilei\" Lecce\n",
      "‚úÖ VTEE820019: Tuscania\n",
      "‚ùå PTOF_TADDIA_2019-2022 .pdf: Codice non estratto\n",
      "‚úÖ COTD01000G: Caio Plinio Secondo\n",
      "‚úÖ LEEE8AT01P: V. Ampolo\n",
      "‚úÖ AGIS00100X: Iis - Ugo Foscolo\n",
      "üîé PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028.pdf: codice estratto dal PDF ‚Üí ME1A14100N\n",
      "‚ö†Ô∏è PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028.pdf: codici trovati ['ME1A14100N', 'ME1E016002', 'ME1EOF500O', 'ME1M00500R', 'ME1MU5500F', 'MEPMEB500L', 'MEPS01500B', 'MEPS435000', 'MEPCPD5001'], scelto ME1A14100N\n",
      "‚úÖ ME1A14100N: S. Ignazio\n",
      "‚úÖ TPAA813018: Plesso \"De Amicis\"\n",
      "üîé PTOF-TRIENNIO-2025-2028.pdf: codice estratto dal PDF ‚Üí NASD04000B\n",
      "‚úÖ NASD04000B: Liceo Artistico Statale-\"G. De Chirico\"\n",
      "‚úÖ PIEE838014: A.Saffi\n",
      "‚úÖ GEIS01400Q: I.S. I. Calvino\n",
      "‚úÖ CZEE87401N: Pl. \"Maggiore Perri\"Ic Perri-Pi\n",
      "‚úÖ MOIS00200C: Primo Levi\n",
      "‚úÖ NOAA825059: \"Elve Fortis De Hieronymis\"\n",
      "‚úÖ CHIS019001: Iis \"De Titta - Fermi\" - Lanciano\n",
      "‚úÖ TPTL01402L: Sez. Stacc. I.T.G. Petrosino\n",
      "‚úÖ SOPS050001: Liceo P.Nervi - G.Ferrari\n",
      "‚úÖ MTIS01200R: I.I.S. \" G.B. Pentasuglia \" -Matera\n",
      "‚úÖ ARSD00201N: Liceo Artistico Anghiari\n",
      "‚úÖ CNAA84803V: Confreria\n",
      "‚úÖ CNIS01100D: Ceva - \"G. Baruffi\"\n",
      "‚úÖ MIPC09500C: Liceo Classico Istituto Gonzaga\n",
      "‚úÖ TPIS002005: I.I.S.S. \"F. D'Aguirre - D. Alighieri\"\n",
      "‚úÖ FIMM825016: Boccaccio\n",
      "‚úÖ CZTE021011: Istituto Tecnico Tecnologico B. Chimirri\n",
      "‚úÖ AVAA871026: Scuola Infanzia-Materdomini\n",
      "‚úÖ NAAA8FV03P: Portici Ic 5 -V.Napoli- Tiziano\n",
      "‚úÖ BAIC818001: I.C. \"Massari Galilei\"\n",
      "‚úÖ BNPS01301P: Sant'Agata De' Goti\n",
      "‚úÖ BORC10500R: Istituto Salesiano Beata Vergine Di San Luca\n",
      "‚úÖ AGAA805076: Garibaldi\n",
      "üîé PTOF-completo-25-28.pdf: codice estratto dal PDF ‚Üí GERI015006\n",
      "‚ö†Ô∏è PTOF-completo-25-28.pdf: codici trovati ['IT08D05387', 'IT73V05034', 'GERI015006'], scelto GERI015006\n",
      "‚úÖ GERI015006: Duchessa Di Galliera\n",
      "‚úÖ BGIS03800B: \"Guido Galli\"\n",
      "‚úÖ TEIS012009: I.I.S. Delfico-Montauti\n",
      "‚úÖ CEPS02000T: Ls Enrico Fermi Aversa\n",
      "‚úÖ MIRFHT500U: Barbara Melzi\n",
      "‚ö†Ô∏è Duplicato MIRFHT500U: tengo PTOF-MIRFHT500U-202225-rev.-2024-25.pdf, scarto MIRFHT500U_PTOF.pdf\n",
      "‚úÖ VAPLVL5003: Liceo Linguistico Collegio Rotondi\n",
      "‚úÖ RGPS00801T: Liceo Scientifico \" Q.Cataudella \"\n",
      "‚úÖ NUAA87003A: Tortoli' - Via Frugoni\n",
      "‚úÖ MIIC836006: Ic Don Lorenzo Milani\n",
      "‚úÖ PAIC87200Q: I.C. Padre Puglisi - Orestano\n",
      "‚ö†Ô∏è Duplicato PAIC87200Q: tengo PAIC87200Q-PTOF_2022_25_-_A.S._2024_25.pdf, scarto PAIC87200Q-PTOF 2022 25 - A.S. 2024 25.pdf\n",
      "‚úÖ TAIC80300X: I.C. \"L. Pirandello\"\n",
      "‚úÖ AVMM81001T: A. Di Meo\n",
      "‚úÖ MBIC8AM00E: Ic Filippo De Pisis/Brugherio\n",
      "‚úÖ CTIS04300B: Marconi-Mangano\n",
      "‚úÖ AQIS01400C: Istituto Superiore Ettore Majorana\n",
      "‚úÖ MIIC8DB00D: Ic Don Milani\n",
      "‚úÖ SVIC81300R: I. C. Varazze-Celle\n",
      "‚úÖ MOIC84800N: 10 I.C. Modena\n",
      "‚úÖ SRPS02301R: L. Scient.-Class-Ling-Sc.Umane Majorana\n",
      "‚úÖ CSIS06700R: Iis S.Marco A. Itcg-Lc Ls Ipa Spezzano A\n",
      "‚úÖ LOIS00300P: I.I.S. Cesaris Di Casalpusterlengo\n",
      "‚úÖ BAEE8A1018: S.G.Bosco - 1 Cd Triggiano\n",
      "üîé FGIC85400C_PTOF.pdf: codice estratto dal PDF ‚Üí FGIC85400C\n",
      "‚ö†Ô∏è FGIC85400C: Non in MIUR (procedo comunque)\n",
      "‚úÖ AGAA83604P: Via Boccaccio\n",
      "‚úÖ BRPM040508: Liceo Don Quirico Punzi Serale\n",
      "‚úÖ UDAA847038: \"Claudio D'Agostina\"\n",
      "‚úÖ ISPS01601E: Liceo Scientifico \"Giovanni Paolo I\"\n",
      "‚úÖ BSTF013014: Orzinuovi (Sez.Ass.I.S.\"Cossali\")\n",
      "‚úÖ PZEE88304R: Giuliano-Ic Busciolano Pz\n",
      "‚úÖ NATF130009: Iti L.Galvani-Giugliano-\n",
      "‚úÖ RMIC8C600P: Ic Anzio V\n",
      "‚úÖ MBAA8EX03X: Via Passirano Nord - Andersen\n",
      "‚úÖ AVTF070004: Itt Guido Dorso\n",
      "‚úÖ PDAA890012: La Giraffa\n",
      "‚úÖ RAIC82800B: I.C. 1 \"Andrea Canevaro\"\n",
      "‚úÖ TPTD02202N: Ist.Tec. Economico \"Sciascia E Bufalino\"\n",
      "‚úÖ BAIC818001: I.C. \"Massari Galilei\"\n",
      "‚ö†Ô∏è Duplicato BAIC818001: tengo BAIC818001-202225-202425-20250106.pdf, scarto BAIC818001_PTOF.pdf\n",
      "‚úÖ PZPS02401A: L. Linguistico \"L. Da Vinci\" Potenza\n",
      "‚úÖ BOIS02700V: I.I.S. Crescenzi-Pacinotti-Sirani\n",
      "‚ö†Ô∏è Duplicato BOIS02700V: tengo PTOF_BOIS02700V_2022-25_aggiornamento_24-25.pdf, scarto PTOF BOIS02700V 2022-25 aggiornamento 24-25.pdf\n",
      "üîé PCPC00500A_PTOF.pdf: codice estratto dal PDF ‚Üí STRUTTURA5\n",
      "‚ö†Ô∏è PCPC00500A_PTOF.pdf: codici trovati ['PCPC00500A', 'STRUTTURA5', 'EFFICACIA8', 'EDUCATIVE9', 'CULTURALI9', 'LINGUAGGI1', 'FAMIGLIE28', 'DIDATTICA3', 'RECUPERO36', 'EDUCATION3', 'CONDOTTA40', 'PROFITTO44', 'PCSPD7500T'], scelto STRUTTURA5\n",
      "‚ö†Ô∏è STRUTTURA5: Non in MIUR (procedo comunque)\n",
      "‚úÖ SSIC80600X: D.A.Azuni - Budduso'\n",
      "‚úÖ RAAA816034: S. Apollinare\n",
      "‚úÖ RMMM8F401X: Goffredo Petrassi\n",
      "‚úÖ MIIS08900V: G. Puecher - A. Olivetti\n",
      "‚úÖ PZMM87413B: \"Aldo Moro\" Gallicchio\n",
      "‚úÖ BNIS02300V: Faicchio\n",
      "‚úÖ VEIC81400N: I.C. U. Foscolo Murano-Burano\n",
      "‚úÖ BAIS05300C: I.I.S.S. \"Luigi Russo\"\n",
      "‚úÖ FGIC85900G: I.C. \"Parisi-De Sanctis\"\n",
      "‚úÖ RMMM847016: Via S. Maria Delle Fornaci 1\n",
      "‚úÖ TAPS180505: D. De Ruggieri Serale\n",
      "‚úÖ MITF19000B: Istituto Tecnico E Liceo - A. Steiner\n",
      "‚úÖ LEEE82703P: Grazia Deledda\n",
      "‚úÖ CASL013016: Iglesias\n",
      "‚úÖ PEEE807059: Torre De' Passeri-C.U.-Ic Manzi\n",
      "‚úÖ VTIC82500A: I.C. Capranica\n",
      "‚úÖ RCEE81209D: Scuola Primaria S.Elia\n",
      "‚úÖ AGPC010001: Liceo Classico - Empedocle\n",
      "‚ùå ELMAS_PTOF.pdf: Codice non estratto\n",
      "‚ö†Ô∏è CTIC823002: Non in MIUR (procedo comunque)\n",
      "‚ö†Ô∏è NAIC80800G: Non in MIUR (procedo comunque)\n",
      "‚úÖ RIRI00701X: I.P.I.A. E. Vanoni\n",
      "‚úÖ KRIS00400C: Giuseppe Gangale\n",
      "‚úÖ VIPS08000D: L.S. \"Da Vinci\" Arzignano\n",
      "‚ö†Ô∏è Duplicato VIPS08000D: tengo VIPS08000D_LS_DA_VINCI_ARZIGNANO.pdf, scarto ARZIGNANO_VIPS08000D.pdf\n",
      "‚úÖ LEMM853025: G. Pascoli - San Donato\n",
      "‚úÖ PEMM81102R: S.M. \"G.Leopardi\" - Moscufo\n",
      "‚úÖ TPAA82505P: Scuola Infanzia \"Ascanio\"\n",
      "‚úÖ BAEE805011: Scuola Primaria\"Giuseppe Verdi\"\n",
      "‚úÖ CRPC02000A: \"Daniele Manin\"\n",
      "‚úÖ CETF046015: Francesco Giordani\n",
      "‚úÖ MEIS03700V: I.I.S. \"A.M.Jaci - Caio Duilio\"\n",
      "‚ö†Ô∏è Duplicato MEIS03700V: tengo PTOF-MEIS03700V-2022-25.pdf, scarto MESSINA_MEIS03700V.pdf\n",
      "‚úÖ PVIS006008: Iis Alessandro Volta - Pavia\n",
      "‚úÖ RGIS01300V: Galileo Ferraris\n",
      "üîé BS1M004009_PTOF.pdf: codice estratto dal PDF ‚Üí BSPC12500Q\n",
      "‚ö†Ô∏è BS1M004009_PTOF.pdf: codici trovati ['BS1M004009', 'BSPC12500Q', 'BSPLLZ5006', 'BSPS06500N'], scelto BSPC12500Q\n",
      "‚úÖ BSPC12500Q: Liceo Classico Quadriennale Madonna Della Neve\n",
      "üîé AVEZZANO_AQPM01000G.pdf: codice estratto dal PDF ‚Üí AQPM01000G\n",
      "‚ö†Ô∏è AQPM01000G: Non in MIUR (procedo comunque)\n",
      "‚úÖ PSIC830007: Fano - G.Padalino\n",
      "üîé BRUGHERIO_MIIC85700P.pdf: codice estratto dal PDF ‚Üí MBIC8AM00E\n",
      "‚ö†Ô∏è BRUGHERIO_MIIC85700P.pdf: codici trovati ['MIIC85700P', 'MBIC8AM00E'], scelto MBIC8AM00E\n",
      "‚úÖ MBIC8AM00E: Ic Filippo De Pisis/Brugherio\n",
      "‚ö†Ô∏è Duplicato MBIC8AM00E: tengo BRUGHERIO_MIIC85700P.pdf, scarto BRUGHERIO_MBIC8AM00E.pdf\n",
      "‚úÖ MIPMU4500Z: Liceo Delle Scienze Umane Opz. Economico Sociale S\n",
      "‚úÖ NAEE177034: S.Giuseppe Ves.1 - Rossilli\n",
      "‚úÖ SOIC82100B: I.C. Sondrio - \"Paesi Orobici\"\n",
      "‚úÖ CLAA81801A: Via Madonna Di Fatima\n",
      "‚úÖ LEAA853021: Giovan Battista De Giorgi\n",
      "‚úÖ NAAA847024: 4 Circolo Didattico Statale\n",
      "‚úÖ CHTF01101V: L.Da Vinci - Iis Da Vinci De G Lanciano\n",
      "‚úÖ ISIS003002: Istituto Omnicomprensivo \"A. Giordano\"\n",
      "‚úÖ AGTF024015: E. Fermi\n",
      "‚úÖ RMMM8DL01V: Sms Via Copenaghen\n",
      "‚ùå PTOF_TADDIA_2019-2022_.pdf: Codice non estratto\n",
      "‚úÖ MOIC84900D: 2 I.C. Ravarino\n",
      "‚úÖ SAAA8AA03R: Salita Garibaldi\n",
      "‚úÖ BORC10500R: Istituto Salesiano Beata Vergine Di San Luca\n",
      "‚ö†Ô∏è Duplicato BORC10500R: tengo BORC10500R_BEATA_VERGINE_DI_SAN_LUCA.pdf, scarto BOLOGNA_BORC10500R.pdf\n",
      "‚úÖ NOAA833036: Infanzia Maggiora\n",
      "‚úÖ ROIS012001: I.I.S. \"Viola-Marchesini\" Rovigo\n",
      "‚úÖ FEIS01400G: Ist.Istruzione Superiore \"F.Lli Taddia\"\n",
      "‚úÖ BNTF02202L: \"Carafa-Giustiniani\" Cerreto S.\n",
      "‚úÖ PTEE82703P: Valenzatico\n",
      "‚úÖ CRIC817004: I.C. Spino D'Adda \"L. Chiesa\"\n",
      "‚úÖ SSPS05000G: Liceo Scientifico Statale Lorenzo Mossa\n",
      "üîé PTOF 2024-25.pdf: codice estratto dal PDF ‚Üí NAPS36000R\n",
      "‚úÖ NAPS36000R: L.Scient.\"Carlo Urbani\"San Giorgio A Cr.\n",
      "\n",
      "üìã PDF riconosciuti: 227\n",
      "üìã PDF da processare (deduplicati): 197\n",
      "\n",
      "======================================================================\n",
      "üìù STEP 1: Conversione PDF ‚Üí Markdown\n",
      "======================================================================\n",
      "üîÑ Convertendo: SATE06901B_PTOF.pdf ‚Üí SATE06901B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: AREE82004B_PTOF.pdf ‚Üí AREE82004B_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: RGAA809032_PTOF.pdf ‚Üí RGAA809032_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: TPAA807022_PTOF.pdf ‚Üí TPAA807022_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: BAAA83103A_PTOF.pdf ‚Üí BAAA83103A_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: NAAA8BW034_PTOF.pdf ‚Üí NAAA8BW034_ptof.md\n",
      "   ‚úÖ Convertito!\n",
      "üîÑ Convertendo: SRPS150012_PTOF.pdf ‚Üí SRPS150012_ptof.md\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 267\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîÑ Convertendo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_path\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ‚Üí \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschool_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ptof.md\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpdf_to_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmd_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    268\u001b[0m         converted\u001b[38;5;241m.\u001b[39mappend((pdf_path, school_code, miur_data))\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ‚úÖ Convertito!\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/git/LIste/src/processing/convert_pdfs_to_md.py:24\u001b[0m, in \u001b[0;36mpdf_to_markdown\u001b[0;34m(pdf_path, output_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m md_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Contenuto PTOF: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(pdf_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc):\n\u001b[0;32m---> 24\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Heuristic formatting\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Convert obvious headers (all caps lines, short lines) to MD headers\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     lines \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/git/LIste/.venv/lib/python3.10/site-packages/pymupdf/__init__.py:12167\u001b[0m, in \u001b[0;36mPage.get_text\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m  12166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m> 12167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/LIste/.venv/lib/python3.10/site-packages/pymupdf/utils.py:503\u001b[0m, in \u001b[0;36mget_text\u001b[0;34m(page, option, clip, flags, textpage, sort, delimiters, tolerance)\u001b[0m\n\u001b[1;32m    501\u001b[0m     t \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mextractXHTML()\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractText\u001b[49m\u001b[43m(\u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m textpage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m tp\n",
      "File \u001b[0;32m~/git/LIste/.venv/lib/python3.10/site-packages/pymupdf/__init__.py:16623\u001b[0m, in \u001b[0;36mTextPage.extractText\u001b[0;34m(self, sort)\u001b[0m\n\u001b[1;32m  16621\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return simple, bare text on the page.\"\"\"\u001b[39;00m\n\u001b[1;32m  16622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort:\n\u001b[0;32m> 16623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extractText\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m  16624\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextractBLOCKS()[:]\n\u001b[1;32m  16625\u001b[0m blocks\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m b: (b[\u001b[38;5;241m3\u001b[39m], b[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m~/git/LIste/.venv/lib/python3.10/site-packages/pymupdf/__init__.py:16427\u001b[0m, in \u001b[0;36mTextPage._extractText\u001b[0;34m(self, format_)\u001b[0m\n\u001b[1;32m  16425\u001b[0m     mupdf\u001b[38;5;241m.\u001b[39mfz_print_stext_page_as_xhtml(out, this_tpage, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m  16426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m> 16427\u001b[0m     \u001b[43mJM_print_stext_page_as_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_tpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  16428\u001b[0m out\u001b[38;5;241m.\u001b[39mfz_close_output()\n\u001b[1;32m  16429\u001b[0m text \u001b[38;5;241m=\u001b[39m JM_EscapeStrFromBuffer(res)\n",
      "File \u001b[0;32m~/git/LIste/.venv/lib/python3.10/site-packages/pymupdf/__init__.py:21167\u001b[0m, in \u001b[0;36mJM_print_stext_page_as_text\u001b[0;34m(res, page)\u001b[0m\n\u001b[1;32m  21161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m  21162\u001b[0m \u001b[38;5;124;03mPlain text output. An identical copy of fz_print_stext_page_as_text,\u001b[39;00m\n\u001b[1;32m  21163\u001b[0m \u001b[38;5;124;03mbut lines within a block are concatenated by space instead a new-line\u001b[39;00m\n\u001b[1;32m  21164\u001b[0m \u001b[38;5;124;03mcharacter (which else leads to 2 new-lines).\u001b[39;00m\n\u001b[1;32m  21165\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m  21166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m g_use_extra:\n\u001b[0;32m> 21167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mextra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJM_print_stext_page_as_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  21169\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, mupdf\u001b[38;5;241m.\u001b[39mFzBuffer)\n\u001b[1;32m  21170\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(page, mupdf\u001b[38;5;241m.\u001b[39mFzStextPage)\n",
      "File \u001b[0;32m~/git/LIste/.venv/lib/python3.10/site-packages/pymupdf/extra.py:165\u001b[0m, in \u001b[0;36mJM_print_stext_page_as_text\u001b[0;34m(res, page)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mJM_print_stext_page_as_text\u001b[39m(res, page):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJM_print_stext_page_as_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# COMPLETO ANALISI PTOF (VERSIONE SEMPLIFICATA)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# üöÄ PDF ‚Üí MD ‚Üí Analisi Multi-Agente ‚Üí JSON (arricchito) ‚Üí rebuild_csv ‚Üí CSV\n",
    "# ‚úÖ Catena dati: Normalizzazioni nel JSON, CSV √® derivato (solo lettura)\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import logging\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configurazione\n",
    "BASE_DIR = Path('/Users/danieledragoni/git/LIste')\n",
    "os.chdir(BASE_DIR)\n",
    "sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "INBOX_DIR = BASE_DIR / \"ptof_inbox\"\n",
    "PROCESSED_DIR = BASE_DIR / \"ptof_processed\"\n",
    "MD_DIR = BASE_DIR / \"ptof_md\"\n",
    "ANALYSIS_DIR = BASE_DIR / \"analysis_results\"\n",
    "CSV_FILE = BASE_DIR / \"data\" / \"analysis_summary.csv\"\n",
    "DOWNLOAD_LOCK = INBOX_DIR / \".download_in_progress\"\n",
    "WAIT_SECONDS = int(os.environ.get(\"PTOF_DOWNLOAD_WAIT_SECONDS\", \"10\"))\n",
    "\n",
    "# Crea directory\n",
    "for d in [INBOX_DIR, PROCESSED_DIR, MD_DIR, ANALYSIS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70, flush=True)\n",
    "print(\"üöÄ WORKFLOW COMPLETO ANALISI PTOF\", flush=True)\n",
    "print(f\"üïê {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", flush=True)\n",
    "print(\"=\"*70, flush=True)\n",
    "\n",
    "# =====================================================\n",
    "# INIZIALIZZAZIONE DATABASE MIUR\n",
    "# =====================================================\n",
    "print(\"\\nüîß Caricamento database...\", flush=True)\n",
    "\n",
    "import src.utils.school_database as school_db_module\n",
    "importlib.reload(school_db_module)\n",
    "from src.utils.school_database import SchoolDatabase\n",
    "\n",
    "SchoolDatabase._instance = None\n",
    "SchoolDatabase._loaded = False\n",
    "SCHOOL_DB = SchoolDatabase()\n",
    "print(f\"   ‚úÖ Database MIUR: {len(SCHOOL_DB._data)} scuole\", flush=True)\n",
    "\n",
    "# Conta PDF\n",
    "while True:\n",
    "    inbox_pdfs = list(INBOX_DIR.glob(\"*.pdf\"))\n",
    "    print(f\"\\nüì• PDF in inbox: {len(inbox_pdfs)}\", flush=True)\n",
    "\n",
    "    if not inbox_pdfs:\n",
    "        if DOWNLOAD_LOCK.exists():\n",
    "            print(f\"‚è≥ Download in corso, attendo {WAIT_SECONDS}s...\", flush=True)\n",
    "            time.sleep(WAIT_SECONDS)\n",
    "            continue\n",
    "        print(\"‚ö†Ô∏è Nessun PDF da processare!\", flush=True)\n",
    "        print(\"üí° Copia i PDF in ptof_inbox/ e riprova\", flush=True)\n",
    "    else:\n",
    "        # =====================================================\n",
    "        # STEP 0: VALIDAZIONE PRE-ANALISI\n",
    "        # =====================================================\n",
    "        print(\"\\n\" + \"=\"*70, flush=True)\n",
    "        print(\"üîç STEP 0: Validazione codici meccanografici\", flush=True)\n",
    "        print(\"=\"*70, flush=True)\n",
    "    \n",
    "        recognized_pdfs = []\n",
    "        process_pdfs = {}\n",
    "        already_analyzed = set()\n",
    "        code_pattern = re.compile(r'([A-Z]{2}[A-Z0-9]{2}[A-Z0-9]{6})', re.IGNORECASE)\n",
    "    \n",
    "        def extract_text_from_pdf(pdf_path, max_pages=4, max_chars=20000):\n",
    "            text_parts = []\n",
    "            total_chars = 0\n",
    "            try:\n",
    "                from pypdf import PdfReader\n",
    "                reader = PdfReader(str(pdf_path))\n",
    "                for i, page in enumerate(reader.pages):\n",
    "                    if i >= max_pages:\n",
    "                        break\n",
    "                    try:\n",
    "                        page_text = page.extract_text() or \"\"\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    text_parts.append(page_text)\n",
    "                    total_chars += len(page_text)\n",
    "                    if total_chars >= max_chars:\n",
    "                        break\n",
    "                return \"\\n\".join(text_parts).strip()\n",
    "            except Exception:\n",
    "                try:\n",
    "                    import fitz\n",
    "                    doc = fitz.open(str(pdf_path))\n",
    "                    for i in range(min(max_pages, len(doc))):\n",
    "                        page_text = doc[i].get_text(\"text\") or \"\"\n",
    "                        text_parts.append(page_text)\n",
    "                        total_chars += len(page_text)\n",
    "                        if total_chars >= max_chars:\n",
    "                            break\n",
    "                    return \"\\n\".join(text_parts).strip()\n",
    "                except Exception:\n",
    "                    return \"\"\n",
    "\n",
    "        def extract_school_code(name, school_db, pdf_path=None):\n",
    "            def dedupe(candidates):\n",
    "                seen = set()\n",
    "                unique = []\n",
    "                for code in candidates:\n",
    "                    if code in seen:\n",
    "                        continue\n",
    "                    seen.add(code)\n",
    "                    unique.append(code)\n",
    "                return unique\n",
    "\n",
    "            def pick_valid(candidates):\n",
    "                if not school_db:\n",
    "                    return None, None\n",
    "                for code in candidates:\n",
    "                    miur_data = school_db.get_school_data(code)\n",
    "                    if miur_data:\n",
    "                        return code, miur_data\n",
    "                return None, None\n",
    "\n",
    "            filename_candidates = code_pattern.findall(name.upper())\n",
    "            filename_candidates = [c for c in filename_candidates if any(ch.isdigit() for ch in c)]\n",
    "            filename_candidates = dedupe(filename_candidates)\n",
    "\n",
    "            code, miur_data = pick_valid(filename_candidates)\n",
    "            if code:\n",
    "                return code, filename_candidates, miur_data, \"filename\"\n",
    "\n",
    "            pdf_candidates = []\n",
    "            if pdf_path is not None:\n",
    "                text = extract_text_from_pdf(pdf_path)\n",
    "                if text:\n",
    "                    pdf_candidates = code_pattern.findall(text.upper())\n",
    "                    pdf_candidates = [c for c in pdf_candidates if any(ch.isdigit() for ch in c)]\n",
    "                    pdf_candidates = dedupe(pdf_candidates)\n",
    "                    code, miur_data = pick_valid(pdf_candidates)\n",
    "                    if code:\n",
    "                        combined = filename_candidates + [c for c in pdf_candidates if c not in filename_candidates]\n",
    "                        return code, combined, miur_data, \"pdf\"\n",
    "\n",
    "            combined = filename_candidates + [c for c in pdf_candidates if c not in filename_candidates]\n",
    "            if pdf_candidates:\n",
    "                return pdf_candidates[0], combined, None, \"pdf\"\n",
    "            if filename_candidates:\n",
    "                return filename_candidates[0], combined, None, \"filename\"\n",
    "            return None, [], None, None\n",
    "\n",
    "        def json_status(path):\n",
    "            if not path.exists():\n",
    "                return 'missing'\n",
    "            if path.stat().st_size == 0:\n",
    "                return 'empty'\n",
    "            try:\n",
    "                json.loads(path.read_text())\n",
    "            except Exception:\n",
    "                return 'invalid'\n",
    "            return 'valid'\n",
    "    \n",
    "        def get_analysis_status(school_code):\n",
    "            candidates = [\n",
    "                ANALYSIS_DIR / f\"{school_code}_PTOF_analysis.json\",\n",
    "                ANALYSIS_DIR / f\"{school_code}_analysis.json\",\n",
    "            ]\n",
    "            statuses = [(path, json_status(path)) for path in candidates]\n",
    "            for path, status in statuses:\n",
    "                if status == 'valid':\n",
    "                    return path, status\n",
    "            for path, status in statuses:\n",
    "                if status in ('empty', 'invalid'):\n",
    "                    return path, status\n",
    "            return candidates[0], 'missing'\n",
    "\n",
    "        def choose_preferred_pdf(current_path, new_path):\n",
    "            current_stat = current_path.stat()\n",
    "            new_stat = new_path.stat()\n",
    "            if new_stat.st_mtime != current_stat.st_mtime:\n",
    "                return new_path if new_stat.st_mtime > current_stat.st_mtime else current_path\n",
    "            if new_stat.st_size != current_stat.st_size:\n",
    "                return new_path if new_stat.st_size > current_stat.st_size else current_path\n",
    "            return current_path\n",
    "    \n",
    "        for pdf_path in inbox_pdfs:\n",
    "            school_code, candidates, miur_data, source = extract_school_code(pdf_path.stem, SCHOOL_DB, pdf_path)\n",
    "            if not school_code:\n",
    "                print(f\"‚ùå {pdf_path.name}: Codice non estratto\", flush=True)\n",
    "                continue\n",
    "            if source == 'pdf':\n",
    "                print(f\"üîé {pdf_path.name}: codice estratto dal PDF ‚Üí {school_code}\", flush=True)\n",
    "            if len(candidates) > 1:\n",
    "                print(f\"‚ö†Ô∏è {pdf_path.name}: codici trovati {candidates}, scelto {school_code}\", flush=True)\n",
    "        \n",
    "            if miur_data:\n",
    "                print(f\"‚úÖ {school_code}: {miur_data.get('denominazione', 'ND')[:50]}\", flush=True)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è {school_code}: Non in MIUR (procedo comunque)\", flush=True)\n",
    "        \n",
    "            recognized_pdfs.append((pdf_path, school_code, miur_data))\n",
    "        \n",
    "            analysis_path, status = get_analysis_status(school_code)\n",
    "\n",
    "            if status == 'valid':\n",
    "                if school_code not in already_analyzed:\n",
    "                    print(f\"‚è≠Ô∏è {school_code}: Analisi gi√† presente ({analysis_path.name})\", flush=True)\n",
    "                    already_analyzed.add(school_code)\n",
    "                continue\n",
    "            if status == 'empty':\n",
    "                print(f\"‚ö†Ô∏è {school_code}: JSON vuoto, rieseguo analisi\", flush=True)\n",
    "            elif status == 'invalid':\n",
    "                print(f\"‚ö†Ô∏è {school_code}: JSON non valido, rieseguo analisi\", flush=True)\n",
    "        \n",
    "            if school_code in process_pdfs:\n",
    "                kept = choose_preferred_pdf(process_pdfs[school_code][0], pdf_path)\n",
    "                if kept == pdf_path:\n",
    "                    print(f\"‚ö†Ô∏è Duplicato {school_code}: tengo {pdf_path.name}, scarto {process_pdfs[school_code][0].name}\", flush=True)\n",
    "                    process_pdfs[school_code] = (pdf_path, school_code, miur_data)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Duplicato {school_code}: tengo {process_pdfs[school_code][0].name}, scarto {pdf_path.name}\", flush=True)\n",
    "                continue\n",
    "        \n",
    "            process_pdfs[school_code] = (pdf_path, school_code, miur_data)\n",
    "    \n",
    "        process_pdfs = list(process_pdfs.values())\n",
    "        print(f\"\\nüìã PDF riconosciuti: {len(recognized_pdfs)}\", flush=True)\n",
    "        print(f\"üìã PDF da processare (deduplicati): {len(process_pdfs)}\", flush=True)\n",
    "    \n",
    "        # =====================================================\n",
    "        # STEP 1: CONVERSIONE PDF ‚Üí MARKDOWN\n",
    "        # =====================================================\n",
    "        print(\"\\n\" + \"=\"*70, flush=True)\n",
    "        print(\"üìù STEP 1: Conversione PDF ‚Üí Markdown\", flush=True)\n",
    "        print(\"=\"*70, flush=True)\n",
    "    \n",
    "        from src.processing.convert_pdfs_to_md import pdf_to_markdown\n",
    "    \n",
    "        converted = []\n",
    "    \n",
    "        for pdf_path, school_code, miur_data in process_pdfs:\n",
    "            md_output = MD_DIR / f\"{school_code}_ptof.md\"\n",
    "        \n",
    "            # Verifica se gi√† analizzato\n",
    "            analysis_path, status = get_analysis_status(school_code)\n",
    "            if status == 'valid':\n",
    "                print(f\"‚è≠Ô∏è Gi√† analizzato: {school_code} ({analysis_path.name})\", flush=True)\n",
    "                continue\n",
    "        \n",
    "            print(f\"üîÑ Convertendo: {pdf_path.name} ‚Üí {school_code}_ptof.md\", flush=True)\n",
    "        \n",
    "            try:\n",
    "                if pdf_to_markdown(str(pdf_path), str(md_output)):\n",
    "                    converted.append((pdf_path, school_code, miur_data))\n",
    "                    print(f\"   ‚úÖ Convertito!\", flush=True)\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Errore conversione\", flush=True)\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Errore: {e}\", flush=True)\n",
    "    \n",
    "        print(f\"\\nüìä Convertiti: {len(converted)} file\", flush=True)\n",
    "    \n",
    "        if converted:\n",
    "            # =====================================================\n",
    "            # STEP 2: ANALISI MULTI-AGENTE\n",
    "            # =====================================================\n",
    "            print(\"\\n\" + \"=\"*70, flush=True)\n",
    "            print(\"ü§ñ STEP 2: Analisi Multi-Agente\", flush=True)\n",
    "            print(\"=\"*70, flush=True)\n",
    "        \n",
    "            # Forza reload del modulo pipeline\n",
    "            import app.agentic_pipeline as agentic_module\n",
    "            importlib.reload(agentic_module)\n",
    "            from app.agentic_pipeline import (\n",
    "                AnalystAgent, RefinerAgent, ReviewerAgent, SynthesizerAgent,\n",
    "                process_single_ptof\n",
    "            )\n",
    "        \n",
    "            analyst = AnalystAgent()\n",
    "            refiner = RefinerAgent()\n",
    "            reviewer = ReviewerAgent()\n",
    "            synthesizer = SynthesizerAgent()\n",
    "        \n",
    "            analyzed = []\n",
    "        \n",
    "            for pdf_path, school_code, miur_data in converted:\n",
    "                md_file = MD_DIR / f\"{school_code}_ptof.md\"\n",
    "            \n",
    "                if not md_file.exists():\n",
    "                    print(f\"‚ö†Ô∏è MD non trovato: {school_code}\", flush=True)\n",
    "                    continue\n",
    "            \n",
    "                print(f\"\\nüìù Analizzando: {school_code}\", flush=True)\n",
    "            \n",
    "                try:\n",
    "                    def status_cb(msg):\n",
    "                        print(f\"   {msg}\", flush=True)\n",
    "                \n",
    "                    # process_single_ptof salva JSON gi√† arricchito (con enrich_json_metadata)\n",
    "                    result = process_single_ptof(\n",
    "                        str(md_file),\n",
    "                        analyst,\n",
    "                        reviewer,\n",
    "                        refiner,\n",
    "                        synthesizer,\n",
    "                        str(ANALYSIS_DIR),\n",
    "                        status_callback=status_cb\n",
    "                    )\n",
    "                \n",
    "                    if result:\n",
    "                        analyzed.append(school_code)\n",
    "                        # Leggi metadati dal JSON salvato per feedback\n",
    "                        json_path = ANALYSIS_DIR / f\"{school_code}_PTOF_analysis.json\"\n",
    "                        with open(json_path, 'r') as f:\n",
    "                            data = json.load(f)\n",
    "                        md_path = ANALYSIS_DIR / f\"{school_code}_PTOF_analysis.md\"\n",
    "                        if not md_path.exists() or md_path.stat().st_size == 0:\n",
    "                            print(\"   ‚ö†Ô∏è Report MD mancante o vuoto (narrativa non generata)\", flush=True)\n",
    "                        meta = data.get('metadata', {})\n",
    "                        print(f\"   ‚úÖ Salvato - {meta.get('provincia', 'ND')}, {meta.get('regione', 'ND')}\", flush=True)\n",
    "                    else:\n",
    "                        print(f\"   ‚ö†Ô∏è Nessun risultato\", flush=True)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Errore analisi: {e}\", flush=True)\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "        \n",
    "            print(f\"\\nüìä Analizzati: {len(analyzed)} file\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # STEP 2.5: AUTO-FILL REGIONI DA COMUNI\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üß≠ STEP 2.5: Auto-fill regioni da comuni\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        ['python3', 'src/processing/autofill_region_from_comuni.py'],\n",
    "        capture_output=True, text=True, cwd=str(BASE_DIR)\n",
    "    )\n",
    "    print(result.stdout, flush=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"‚ö†Ô∏è Errore: {result.stderr}\", flush=True)\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP 3: REBUILD CSV DA JSON\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üìä STEP 3: Rebuild CSV da JSON\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    # Esegui rebuild_csv_clean.py\n",
    "    result = subprocess.run(\n",
    "        ['python3', 'src/processing/rebuild_csv_clean.py'],\n",
    "        capture_output=True, text=True, cwd=str(BASE_DIR)\n",
    "    )\n",
    "    print(result.stdout, flush=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"‚ö†Ô∏è Errore: {result.stderr}\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # STEP 4: VERIFICA CSV FINALE\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üìä STEP 4: Verifica CSV\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    if CSV_FILE.exists():\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(CSV_FILE)\n",
    "        print(f\"üìä CSV contiene {len(df)} scuole\", flush=True)\n",
    "        print(f\"\\nColonne principali:\", flush=True)\n",
    "        print(df[['school_id', 'denominazione', 'provincia', 'regione', 'area_geografica', 'ptof_orientamento_maturity_index']].to_string(), flush=True)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è CSV non ancora creato\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # STEP 5: SPOSTA PDF PROCESSATI\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üì¶ STEP 5: Organizzazione file processati\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    batch_dir = PROCESSED_DIR / f\"batch_{timestamp}\"\n",
    "    batch_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    processed_count = 0\n",
    "    for pdf_path, school_code, _ in recognized_pdfs:\n",
    "        analysis_path, status = get_analysis_status(school_code)\n",
    "        if status == 'valid':\n",
    "            dest = batch_dir / pdf_path.name\n",
    "            shutil.move(str(pdf_path), str(dest))\n",
    "            processed_count += 1\n",
    "            print(f\"üì¶ Spostato: {pdf_path.name}\", flush=True)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Analisi non valida ({analysis_path.name}), non sposto: {pdf_path.name}\", flush=True)\n",
    "    \n",
    "    print(f\"\\nüìä PDF spostati in batch: {processed_count}\", flush=True)\n",
    "    \n",
    "    # =====================================================\n",
    "    # RIEPILOGO FINALE\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70, flush=True)\n",
    "    print(\"üìä RIEPILOGO FINALE\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    \n",
    "    final_count = len(list(ANALYSIS_DIR.glob(\"*_analysis.json\")))\n",
    "    print(f\"üìÅ Totale analisi JSON: {final_count}\", flush=True)\n",
    "    print(f\"üìä CSV generato: {CSV_FILE}\", flush=True)\n",
    "    print(f\"\\nüí° Catena dati:\", flush=True)\n",
    "    print(f\"   JSON (verit√†) ‚Üí rebuild_csv_clean.py ‚Üí CSV (derivato)\", flush=True)\n",
    "    print(f\"\\nüöÄ Avvia dashboard: streamlit run app/Home.py\", flush=True)\n",
    "    print(\"=\"*70, flush=True)\n",
    "    if DOWNLOAD_LOCK.exists():\n",
    "        print(f\"\\n‚è≥ Download in corso, attendo {WAIT_SECONDS}s per nuovi PDF...\", flush=True)\n",
    "        time.sleep(WAIT_SECONDS)\n",
    "        continue\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
