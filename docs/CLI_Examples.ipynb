{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üñ•Ô∏è CLI Examples - PTOF Analysis System\n",
                "\n",
                "Questo notebook contiene tutti gli snippet di codice per utilizzare gli script CLI del sistema di analisi PTOF.\n",
                "\n",
                "**‚öôÔ∏è Configurazione**: Tutti i comandi utilizzano il virtual environment `.venv` del progetto.\n",
                "\n",
                "**üìÇ Struttura Directory**:\n",
                "- `ptof_inbox/` ‚Üí PDF da analizzare (INSERISCI QUI)\n",
                "- `ptof_processed/` ‚Üí PDF archiviati automaticamente\n",
                "\n",
                "## üìë Indice\n",
                "1. [üöÄ **Workflow Automatico**](#workflow-automatico) ‚≠ê PRIORIT√Ä\n",
                "2. [üîó Analisi Multi-Agente Batch](#multi-agent-batch)\n",
                "3. [‚òÅÔ∏è Cloud Agent](#cloud-agent)\n",
                "4. [üîç Analisi e Revisione](#analysis-review)\n",
                "5. [üõ†Ô∏è Utility](#utilities)\n",
                "6. [ü§ñ Automazione Background](#background-automation)\n",
                "7. [üìä Diagnostica](#diagnostics)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üöÄ Workflow Automatico {#workflow-automatico}\n",
                "\n",
                "### ‚≠ê Pipeline Completa: Inbox ‚Üí Processed\n",
                "\n",
                "**Cosa fa**:\n",
                "1. üì• Legge PDF da `ptof_inbox/`\n",
                "2. üìù Converte PDF ‚Üí Markdown\n",
                "3. ü§ñ Analizza con pipeline multi-agente\n",
                "4. üì¶ Sposta PDF in `ptof_processed/batch_TIMESTAMP/`\n",
                "5. üìä Aggiorna CSV dashboard"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üöÄ WORKFLOW AUTOMATICO PTOF\n",
                        "üì• Input: ptof_inbox/\n",
                        "‚úÖ Output: ptof_processed/batch_TIMESTAMP/\n",
                        "========================================\n",
                        "2025-12-21 21:54:28,853 - INFO - üìÇ Directory verificata: ptof_inbox/\n",
                        "2025-12-21 21:54:28,854 - INFO - üìÇ Directory verificata: ptof_processed/\n",
                        "2025-12-21 21:54:28,854 - INFO - üìÇ Directory verificata: ptof_md/\n",
                        "2025-12-21 21:54:28,854 - INFO - üìÇ Directory verificata: analysis_results/\n",
                        "2025-12-21 21:54:28,854 - INFO - üìÇ Directory verificata: logs/\n",
                        "2025-12-21 21:54:28,854 - INFO - ================================================================================\n",
                        "2025-12-21 21:54:28,854 - INFO - üöÄ AVVIO WORKFLOW PTOF COMPLETO\n",
                        "2025-12-21 21:54:28,854 - INFO - üïê Timestamp: 2025-12-21 21:54:28\n",
                        "2025-12-21 21:54:28,854 - INFO - ================================================================================\n",
                        "2025-12-21 21:54:28,855 - INFO - \n",
                        "üìä STATO INIZIALE:\n",
                        "2025-12-21 21:54:28,855 - INFO -   PDF in inbox: 2\n",
                        "2025-12-21 21:54:28,855 - INFO -   PDF processati: 0\n",
                        "2025-12-21 21:54:28,855 - INFO -   File Markdown: 105\n",
                        "2025-12-21 21:54:28,855 - INFO -   File analisi: 89\n",
                        "2025-12-21 21:54:28,855 - INFO - ================================================================================\n",
                        "2025-12-21 21:54:28,855 - INFO - üìù STEP 1: Conversione PDF ‚Üí Markdown\n",
                        "2025-12-21 21:54:28,855 - INFO - üìÑ Trovati 2 PDF da convertire\n",
                        "2025-12-21 21:54:29,265 - INFO - ‚úÖ Convertito: PTOF-Marconi-Mangano-2022-25\n",
                        "2025-12-21 21:54:30,003 - INFO - ‚úÖ Convertito: PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028\n",
                        "2025-12-21 21:54:30,003 - INFO - üìä Convertiti 2/2 file\n",
                        "2025-12-21 21:54:30,004 - INFO - ================================================================================\n",
                        "2025-12-21 21:54:30,004 - INFO - ü§ñ STEP 2: Analisi Multi-Agente\n",
                        "2025-12-21 21:54:32,600 - INFO - üìÑ File da analizzare: 2\n",
                        "2025-12-21 21:54:32,600 - INFO - üîÑ Processando: PTOF-Marconi-Mangano-2022-25\n",
                        "2025-12-21 21:54:32,601 - INFO -   [PIPELINE] Processing PTOF-Marconi-Mangano-2022-25...\n",
                        "2025-12-21 21:54:32,601 - INFO - [Pipeline] Long document (218263 chars) - using chunked analysis\n",
                        "2025-12-21 21:54:32,601 - INFO -   [PIPELINE] Long doc (218k chars) - chunking...\n",
                        "2025-12-21 21:54:32,612 - INFO - [Pipeline] Split into 7 chunks\n",
                        "2025-12-21 21:54:32,612 - INFO -   [PIPELINE] Analyst: Chunk 1/7...\n",
                        "2025-12-21 21:54:32,612 - INFO - [gemma3:27b] Drafting chunk 1/7...\n",
                        "2025-12-21 21:55:06,362 - INFO -   [PIPELINE] Analyst: Chunk 2/7...\n",
                        "2025-12-21 21:55:06,362 - INFO - [gemma3:27b] Drafting chunk 2/7...\n",
                        "2025-12-21 21:55:51,472 - INFO -   [PIPELINE] Analyst: Chunk 3/7...\n",
                        "2025-12-21 21:55:51,472 - INFO - [gemma3:27b] Drafting chunk 3/7...\n",
                        "2025-12-21 21:56:31,442 - INFO -   [PIPELINE] Analyst: Chunk 4/7...\n",
                        "2025-12-21 21:56:31,460 - INFO - [gemma3:27b] Drafting chunk 4/7...\n",
                        "2025-12-21 21:57:04,855 - INFO -   [PIPELINE] Analyst: Chunk 5/7...\n",
                        "2025-12-21 21:57:04,855 - INFO - [gemma3:27b] Drafting chunk 5/7...\n",
                        "2025-12-21 21:57:44,919 - INFO -   [PIPELINE] Analyst: Chunk 6/7...\n",
                        "2025-12-21 21:57:44,919 - INFO - [gemma3:27b] Drafting chunk 6/7...\n",
                        "2025-12-21 21:58:24,568 - WARNING - [Pipeline] Chunk 6 parse failed\n",
                        "2025-12-21 21:58:24,581 - INFO -   [PIPELINE] Analyst: Chunk 7/7...\n",
                        "2025-12-21 21:58:24,581 - INFO - [gemma3:27b] Drafting chunk 7/7...\n",
                        "2025-12-21 21:59:08,825 - INFO -   [PIPELINE] Synthesizer: Combining results...\n",
                        "2025-12-21 21:59:08,826 - INFO - [gemma3:27b] Synthesizing 6 partial results...\n",
                        "2025-12-21 22:00:03,054 - INFO - Extracting metadata with Cloud LLM...\n",
                        "[cloud_review] Identifying school metadata via Cloud (Context: 30000 chars)...\n",
                        "Gemini API error: 429 - {\n",
                        "  \"error\": {\n",
                        "    \"code\": 429,\n",
                        "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-a\n",
                        "2025-12-21 22:00:03,453 - INFO - Enriched metadata for PTOF-Marconi-Mangano-2022-25\n",
                        "2025-12-21 22:00:03,453 - INFO -   [PIPELINE] Reviewer: Critiquing...\n",
                        "2025-12-21 22:00:03,453 - INFO - [qwen3:32b] Critiquing report...\n",
                        "2025-12-21 22:00:03,453 - ERROR - [Reviewer] draft_report is None or empty!\n",
                        "2025-12-21 22:00:03,453 - WARNING - Reviewer returned None - skipping review step\n",
                        "2025-12-21 22:00:03,453 - INFO - Report approved directly or no critique available.\n",
                        "2025-12-21 22:00:03,453 - INFO - ‚úÖ Completato: PTOF-Marconi-Mangano-2022-25\n",
                        "2025-12-21 22:00:03,453 - INFO - üîÑ Processando: PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028\n",
                        "2025-12-21 22:00:03,454 - INFO -   [PIPELINE] Processing PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028...\n",
                        "2025-12-21 22:00:03,455 - INFO - [Pipeline] Long document (356542 chars) - using chunked analysis\n",
                        "2025-12-21 22:00:03,455 - INFO -   [PIPELINE] Long doc (356k chars) - chunking...\n",
                        "2025-12-21 22:00:03,467 - INFO - [Pipeline] Split into 10 chunks\n",
                        "2025-12-21 22:00:03,468 - INFO -   [PIPELINE] Analyst: Chunk 1/10...\n",
                        "2025-12-21 22:00:03,468 - INFO - [gemma3:27b] Drafting chunk 1/10...\n",
                        "2025-12-21 22:00:35,629 - INFO -   [PIPELINE] Analyst: Chunk 2/10...\n",
                        "2025-12-21 22:00:35,629 - INFO - [gemma3:27b] Drafting chunk 2/10...\n",
                        "2025-12-21 22:01:18,339 - INFO -   [PIPELINE] Analyst: Chunk 3/10...\n",
                        "2025-12-21 22:01:18,339 - INFO - [gemma3:27b] Drafting chunk 3/10...\n",
                        "2025-12-21 22:01:59,206 - INFO -   [PIPELINE] Analyst: Chunk 4/10...\n",
                        "2025-12-21 22:01:59,206 - INFO - [gemma3:27b] Drafting chunk 4/10...\n",
                        "2025-12-21 22:02:37,720 - INFO -   [PIPELINE] Analyst: Chunk 5/10...\n",
                        "2025-12-21 22:02:37,720 - INFO - [gemma3:27b] Drafting chunk 5/10...\n",
                        "2025-12-21 22:03:16,132 - INFO -   [PIPELINE] Analyst: Chunk 6/10...\n",
                        "2025-12-21 22:03:16,132 - INFO - [gemma3:27b] Drafting chunk 6/10...\n",
                        "2025-12-21 22:04:03,817 - INFO -   [PIPELINE] Analyst: Chunk 7/10...\n",
                        "2025-12-21 22:04:03,818 - INFO - [gemma3:27b] Drafting chunk 7/10...\n",
                        "2025-12-21 22:04:45,243 - INFO -   [PIPELINE] Analyst: Chunk 8/10...\n",
                        "2025-12-21 22:04:45,244 - INFO - [gemma3:27b] Drafting chunk 8/10...\n",
                        "2025-12-21 22:05:12,726 - INFO -   [PIPELINE] Analyst: Chunk 9/10...\n",
                        "2025-12-21 22:05:12,727 - INFO - [gemma3:27b] Drafting chunk 9/10...\n",
                        "2025-12-21 22:05:56,956 - INFO -   [PIPELINE] Analyst: Chunk 10/10...\n",
                        "2025-12-21 22:05:56,957 - INFO - [gemma3:27b] Drafting chunk 10/10...\n",
                        "2025-12-21 22:06:41,522 - INFO -   [PIPELINE] Synthesizer: Combining results...\n",
                        "2025-12-21 22:06:41,524 - INFO - [gemma3:27b] Synthesizing 10 partial results...\n",
                        "2025-12-21 22:07:29,716 - INFO - Extracting metadata with Cloud LLM...\n",
                        "[cloud_review] Identifying school metadata via Cloud (Context: 30000 chars)...\n",
                        "Gemini API error: 429 - {\n",
                        "  \"error\": {\n",
                        "    \"code\": 429,\n",
                        "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-a\n",
                        "2025-12-21 22:07:30,160 - INFO - Enriched metadata for ISTITUTO\n",
                        "2025-12-21 22:07:30,160 - INFO -   [PIPELINE] Reviewer: Critiquing...\n",
                        "2025-12-21 22:07:30,160 - INFO - [qwen3:32b] Critiquing report...\n",
                        "2025-12-21 22:07:30,161 - ERROR - [Reviewer] draft_report is None or empty!\n",
                        "2025-12-21 22:07:30,161 - WARNING - Reviewer returned None - skipping review step\n",
                        "2025-12-21 22:07:30,161 - INFO - Report approved directly or no critique available.\n",
                        "2025-12-21 22:07:30,162 - INFO - ‚úÖ Completato: PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028\n",
                        "2025-12-21 22:07:30,162 - INFO - üìä Analizzati 2/2 file\n",
                        "2025-12-21 22:07:30,162 - INFO - ================================================================================\n",
                        "2025-12-21 22:07:30,163 - INFO - ÔøΩÔøΩÔøΩ STEP 3: Archiviazione PDF Processati\n",
                        "2025-12-21 22:07:30,163 - INFO - üìÅ Directory batch: ptof_processed/batch_20251221_220730\n",
                        "2025-12-21 22:07:30,164 - INFO - ‚úÖ Archiviato: PTOF-Marconi-Mangano-2022-25.pdf\n",
                        "2025-12-21 22:07:30,164 - INFO - ‚úÖ Archiviato: PTOF-ISTITUTO-COLLEGIO-S.-IGNAZIO-2025-2028.pdf\n",
                        "2025-12-21 22:07:30,164 - INFO - üìä Archiviati 2/2 PDF\n",
                        "2025-12-21 22:07:30,164 - INFO - üìÑ Creato riepilogo: ptof_processed/batch_20251221_220730/README.txt\n",
                        "2025-12-21 22:07:30,164 - INFO - ================================================================================\n",
                        "2025-12-21 22:07:30,164 - INFO - üìä STEP 4: Ricostruzione CSV\n",
                        "2025-12-21 22:07:33,205 - INFO - ‚úÖ CSV ricostruito con successo\n",
                        "2025-12-21 22:07:33,206 - INFO - \n",
                        "================================================================================\n",
                        "2025-12-21 22:07:33,206 - INFO - üìä STATO FINALE:\n",
                        "2025-12-21 22:07:33,207 - INFO -   PDF in inbox: 0\n",
                        "2025-12-21 22:07:33,207 - INFO -   PDF processati: 2\n",
                        "2025-12-21 22:07:33,207 - INFO -   File Markdown: 105\n",
                        "2025-12-21 22:07:33,207 - INFO -   File analisi: 91\n",
                        "2025-12-21 22:07:33,207 - INFO - \n",
                        "================================================================================\n",
                        "2025-12-21 22:07:33,207 - INFO - ‚úÖ WORKFLOW COMPLETATO!\n",
                        "2025-12-21 22:07:33,207 - INFO - üìã Log salvato in: logs/workflow_ptof.log\n",
                        "2025-12-21 22:07:33,207 - INFO - üìä Verifica risultati su Dashboard ‚Üí Pagina ‚öôÔ∏è Gestione\n",
                        "2025-12-21 22:07:33,207 - INFO - ================================================================================\n",
                        "========================================\n",
                        "‚úÖ Workflow completato!\n",
                        "üìã Log: logs/workflow_ptof.log\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "# WORKFLOW COMPLETO - Inbox ‚Üí Processed\n",
                "cd /Users/danieledragoni/git/LIste\n",
                "source .venv/bin/activate\n",
                "\n",
                "echo \"üöÄ WORKFLOW AUTOMATICO PTOF\"\n",
                "echo \"üì• Input: ptof_inbox/\"\n",
                "echo \"‚úÖ Output: ptof_processed/batch_TIMESTAMP/\"\n",
                "echo \"========================================\"\n",
                "\n",
                "python workflow_ptof.py 2>&1 | tee logs/workflow_ptof.log\n",
                "\n",
                "echo \"========================================\"\n",
                "echo \"‚úÖ Workflow completato!\"\n",
                "echo \"üìã Log: logs/workflow_ptof.log\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Verifica Stato Directory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "cd /Users/danieledragoni/git/LIste\n",
                "\n",
                "echo \"üìä STATO DIRECTORY\"\n",
                "echo \"========================================\"\n",
                "echo \"üì• Inbox PDF: $(find ptof_inbox -name '*.pdf' 2>/dev/null | wc -l)\"\n",
                "echo \"‚úÖ Processed PDF: $(find ptof_processed -name '*.pdf' 2>/dev/null | wc -l)\"\n",
                "echo \"üìù Markdown: $(find ptof_md -name '*.md' 2>/dev/null | wc -l)\"\n",
                "echo \"üìä Analisi JSON: $(find analysis_results -name '*.json' 2>/dev/null | wc -l)\"\n",
                "echo \"========================================\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üîó Analisi Multi-Agente Batch {#multi-agent-batch}\n",
                "\n",
                "### Pipeline Multi-Agente per Cartella Completa\n",
                "Processa tutti i file PTOF in una cartella usando l'architettura multi-agente (Analyst ‚Üí Reviewer ‚Üí Refiner ‚Üí Synthesizer)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "# Pipeline Multi-Agente - Batch completo su cartella ptof_md/\n",
                "cd /Users/danieledragoni/git/LIste\n",
                "source .venv/bin/activate\n",
                "\n",
                "echo \"üöÄ Avvio Pipeline Multi-Agente Batch\"\n",
                "echo \"üìÇ Directory: ptof_md/\"\n",
                "echo \"ü§ñ Agenti: Analyst ‚Üí Reviewer ‚Üí Refiner\"\n",
                "echo \"========================================\"\n",
                "\n",
                "python app/agentic_pipeline.py 2>&1 | tee logs/agentic_pipeline.log\n",
                "\n",
                "echo \"========================================\"\n",
                "echo \"‚úÖ Pipeline completata!\"\n",
                "echo \"üìã Log: logs/agentic_pipeline.log\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pipeline Multi-Agente - Singolo File con Logging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pipeline Multi-Agente - Modalit√† singolo file con logging dettagliato\n",
                "import sys\n",
                "import os\n",
                "import logging\n",
                "from datetime import datetime\n",
                "\n",
                "# Setup logging\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
                "    handlers=[\n",
                "        logging.FileHandler('logs/single_analysis.log'),\n",
                "        logging.StreamHandler()\n",
                "    ]\n",
                ")\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "# Aggiungi path progetto\n",
                "sys.path.insert(0, '/Users/danieledragoni/git/LIste')\n",
                "\n",
                "from app.agentic_pipeline import (\n",
                "    process_single_ptof,\n",
                "    AnalystAgent,\n",
                "    ReviewerAgent,\n",
                "    RefinerAgent,\n",
                "    SynthesizerAgent\n",
                ")\n",
                "\n",
                "logger.info(\"üöÄ Inizializzazione agenti multi-agente\")\n",
                "\n",
                "# Inizializza agenti\n",
                "analyst = AnalystAgent()\n",
                "reviewer = ReviewerAgent()\n",
                "refiner = RefinerAgent()\n",
                "synthesizer = SynthesizerAgent()\n",
                "\n",
                "logger.info(\"‚úÖ Agenti inizializzati con successo\")\n",
                "\n",
                "# Status callback con logging\n",
                "def status_callback(msg):\n",
                "    logger.info(f\"[PIPELINE] {msg}\")\n",
                "\n",
                "# Processa un singolo file PTOF\n",
                "md_file = \"ptof_md/MIIS08900V.md\"  # Modifica con il tuo file\n",
                "logger.info(f\"üìÑ Processando file: {md_file}\")\n",
                "\n",
                "start_time = datetime.now()\n",
                "\n",
                "result = process_single_ptof(\n",
                "    md_file=md_file,\n",
                "    analyst=analyst,\n",
                "    reviewer=reviewer,\n",
                "    refiner=refiner,\n",
                "    synthesizer=synthesizer,\n",
                "    status_callback=status_callback\n",
                ")\n",
                "\n",
                "elapsed = (datetime.now() - start_time).total_seconds()\n",
                "\n",
                "logger.info(\"=\"*80)\n",
                "logger.info(f\"‚úÖ Analisi completata in {elapsed:.1f} secondi!\")\n",
                "logger.info(f\"üìä Risultato keys: {list(result.keys()) if result else 'None'}\")\n",
                "logger.info(f\"üìã Log salvato in: logs/single_analysis.log\")\n",
                "\n",
                "if result:\n",
                "    metadata = result.get('metadata', {})\n",
                "    logger.info(f\"üè´ Scuola: {metadata.get('denominazione', 'N/A')}\")\n",
                "    logger.info(f\"üìç Comune: {metadata.get('comune', 'N/A')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ‚òÅÔ∏è Cloud Agent {#cloud-agent}\n",
                "\n",
                "### Analisi Cloud con Logging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cloud Agent - Analisi completa con logging dettagliato\n",
                "import sys\n",
                "import logging\n",
                "from datetime import datetime\n",
                "\n",
                "sys.path.insert(0, '/Users/danieledragoni/git/LIste')\n",
                "\n",
                "# Setup logging\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
                "    handlers=[\n",
                "        logging.FileHandler('logs/cloud_analysis.log'),\n",
                "        logging.StreamHandler()\n",
                "    ]\n",
                ")\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "from src.processing.cloud_review import review_ptof_with_cloud, load_api_config\n",
                "\n",
                "logger.info(\"‚òÅÔ∏è Inizializzazione Cloud Agent\")\n",
                "\n",
                "# Carica configurazione API dal file JSON\n",
                "config = load_api_config()\n",
                "provider = config.get('default_provider', 'gemini')\n",
                "api_key_field = f'{provider}_api_key'\n",
                "\n",
                "logger.info(f\"üîê Provider: {provider}\")\n",
                "logger.info(f\"üîë API Key: {'‚úÖ Configurata' if config.get(api_key_field) else '‚ùå Mancante'}\")\n",
                "\n",
                "# Carica il contenuto del file MD\n",
                "md_file = 'ptof_md/MIIS08900V.md'\n",
                "logger.info(f\"üìÑ Caricando file: {md_file}\")\n",
                "\n",
                "with open(md_file, 'r', encoding='utf-8') as f:\n",
                "    text = f.read()\n",
                "\n",
                "logger.info(f\"üìè Dimensione documento: {len(text):,} caratteri\")\n",
                "\n",
                "# Esegui analisi completa\n",
                "start_time = datetime.now()\n",
                "logger.info(\"üöÄ Avvio analisi cloud...\")\n",
                "\n",
                "result = review_ptof_with_cloud(\n",
                "    md_content=text,\n",
                "    provider=provider,\n",
                "    api_key=config.get(api_key_field),\n",
                "    model=\"gemini-2.0-flash-exp\" if provider == 'gemini' else \"google/gemini-2.0-flash-exp:free\",\n",
                "    school_id=\"MIIS08900V\"\n",
                ")\n",
                "\n",
                "elapsed = (datetime.now() - start_time).total_seconds()\n",
                "\n",
                "logger.info(\"=\"*80)\n",
                "logger.info(f\"‚úÖ Analisi completata in {elapsed:.1f} secondi!\")\n",
                "\n",
                "if result:\n",
                "    metadata = result.get('metadata', {})\n",
                "    logger.info(f\"üè´ School ID: {metadata.get('school_id', 'N/A')}\")\n",
                "    logger.info(f\"üìõ Denominazione: {metadata.get('denominazione', 'N/A')}\")\n",
                "    logger.info(f\"üìç Comune: {metadata.get('comune', 'N/A')}\")\n",
                "    logger.info(f\"üó∫Ô∏è Area: {metadata.get('area_geografica', 'N/A')}\")\n",
                "    \n",
                "logger.info(f\"üìã Log salvato in: logs/cloud_analysis.log\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üîç Analisi e Revisione {#analysis-review}\n",
                "\n",
                "### Rebuild CSV con Logging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "# Rebuild CSV - Ricostruzione indice da file JSON\n",
                "cd /Users/danieledragoni/git/LIste\n",
                "source .venv/bin/activate\n",
                "\n",
                "echo \"üìä Ricostruzione CSV da file JSON\"\n",
                "echo \"üìÇ Input: analysis_results/*.json\"\n",
                "echo \"üìÑ Output: data/analysis_summary.csv\"\n",
                "echo \"========================================\"\n",
                "\n",
                "python src/processing/rebuild_csv.py 2>&1 | tee logs/rebuild_csv.log\n",
                "\n",
                "echo \"========================================\"\n",
                "echo \"‚úÖ CSV ricostruito!\"\n",
                "echo \"üìã Log: logs/rebuild_csv.log\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üõ†Ô∏è Utility {#utilities}\n",
                "\n",
                "### Conversione PDF ‚Üí Markdown con Logging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "# Conversione PDF ‚Üí Markdown\n",
                "cd /Users/danieledragoni/git/LIste\n",
                "source .venv/bin/activate\n",
                "\n",
                "echo \"üîÑ Conversione PDF ‚Üí Markdown\"\n",
                "echo \"üìÇ Input: ptof/*.pdf\"\n",
                "echo \"üìÇ Output: ptof_md/*.md\"\n",
                "echo \"========================================\"\n",
                "\n",
                "python src/processing/convert_pdfs_to_md.py 2>&1 | tee logs/pdf_conversion.log\n",
                "\n",
                "echo \"========================================\"\n",
                "echo \"‚úÖ Conversione completata!\"\n",
                "echo \"üìã Log: logs/pdf_conversion.log\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ü§ñ Automazione Background {#background-automation}\n",
                "\n",
                "### Background Fixer - CLI con Logging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "# Background Fixer - Correzione automatica anomalie\n",
                "cd /Users/danieledragoni/git/LIste\n",
                "source .venv/bin/activate\n",
                "\n",
                "echo \"üõ†Ô∏è Background Fixer - Avvio\"\n",
                "echo \"üìÇ Input: data/review_flags.json\"\n",
                "echo \"üìÇ Output: analysis_results/\"\n",
                "echo \"ü§ñ Modello: qwen2.5-coder:7b (Ollama)\"\n",
                "echo \"========================================\"\n",
                "\n",
                "python run_fixer.py 2>&1 | tee logs/background_fixer.log\n",
                "\n",
                "echo \"========================================\"\n",
                "echo \"‚úÖ Correzione completata!\"\n",
                "echo \"üìã Log: logs/background_fixer.log\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìä Diagnostica {#diagnostics}\n",
                "\n",
                "### Verifica Stato Sistema Completo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System Status Check - Diagnostica completa con logging\n",
                "import os\n",
                "import json\n",
                "import logging\n",
                "from glob import glob\n",
                "from datetime import datetime\n",
                "\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
                "    handlers=[\n",
                "        logging.FileHandler('logs/system_diagnostics.log'),\n",
                "        logging.StreamHandler()\n",
                "    ]\n",
                ")\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "logger.info(\"=\"*80)\n",
                "logger.info(\"üìä DIAGNOSTICA SISTEMA PTOF ANALYSIS\")\n",
                "logger.info(f\"üïê Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
                "logger.info(\"=\"*80)\n",
                "\n",
                "# Check review flags\n",
                "logger.info(\"\\nüö© ANOMALIE RILEVATE\")\n",
                "if os.path.exists(\"data/review_flags.json\"):\n",
                "    with open(\"data/review_flags.json\", 'r') as f:\n",
                "        flags = json.load(f)\n",
                "    logger.info(f\"  File con anomalie: {len(flags)}\")\n",
                "else:\n",
                "    logger.info(\"  Nessun file di anomalie trovato\")\n",
                "\n",
                "# Count files\n",
                "logger.info(\"\\nüìÑ FILE SISTEMA\")\n",
                "json_files = glob(\"analysis_results/*.json\")\n",
                "logger.info(f\"  File analisi JSON: {len(json_files)}\")\n",
                "\n",
                "md_files = glob(\"ptof_md/*.md\")\n",
                "logger.info(f\"  File Markdown: {len(md_files)}\")\n",
                "\n",
                "pdf_inbox = glob(\"ptof_inbox/*.pdf\")\n",
                "logger.info(f\"  PDF in inbox: {len(pdf_inbox)}\")\n",
                "\n",
                "# API Configuration\n",
                "logger.info(\"\\nüîê CONFIGURAZIONE API\")\n",
                "if os.path.exists(\"data/api_config.json\"):\n",
                "    with open(\"data/api_config.json\", 'r') as f:\n",
                "        api_config = json.load(f)\n",
                "    logger.info(f\"  Default Provider: {api_config.get('default_provider', 'N/A')}\")\n",
                "    logger.info(f\"  Gemini API: {'‚úÖ' if api_config.get('gemini_api_key') else '‚ùå'}\")\n",
                "    logger.info(f\"  OpenRouter API: {'‚úÖ' if api_config.get('openrouter_api_key') else '‚ùå'}\")\n",
                "\n",
                "logger.info(\"\\n=\"*80)\n",
                "logger.info(\"‚úÖ Diagnostica completata!\")\n",
                "logger.info(\"üìã Log: logs/system_diagnostics.log\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìù Note\n",
                "\n",
                "### Best Practices\n",
                "\n",
                "- ‚úÖ **Virtual Environment**: Tutti i comandi usano `.venv`\n",
                "- ‚úÖ **Logging**: Ogni operazione salva log in `logs/`\n",
                "- ‚úÖ **Workflow Automatico**: Usa `workflow_ptof.py` per processare nuovi PDF\n",
                "- ‚ö†Ô∏è **API Keys**: Configurate in `data/api_config.json`\n",
                "- ‚ö†Ô∏è **Ollama**: Deve essere in esecuzione per pipeline multi-agente\n",
                "\n",
                "### Directory\n",
                "\n",
                "- `ptof_inbox/` - PDF da analizzare\n",
                "- `ptof_processed/` - PDF archiviati\n",
                "- `ptof_md/` - Markdown generati\n",
                "- `analysis_results/` - JSON analisi\n",
                "- `logs/` - File di log"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
